{"db":[{"meta":{"exported_on":1466301990507,"version":"003"},"data":{"posts":[{"id":1,"uuid":"28e5dce9-15c9-4ca3-a24a-efbbd25b581a","title":"Welcome to Ghost","slug":"welcome-to-ghost","markdown":"You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at `<your blog URL>/ghost/`. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!\n\n## Getting Started\n\nGhost uses something called Markdown for writing. Essentially, it's a shorthand way to manage your post formatting as you write!\n\nWriting in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use *shortcuts* to **style** your content. For example, a list:\n\n* Item number one\n* Item number two\n    * A nested item\n* A final item\n\nor with numbers!\n\n1. Remember to buy some milk\n2. Drink the milk\n3. Tweet that I remembered to buy the milk, and drank it\n\n### Links\n\nWant to link to a source? No problem. If you paste in a URL, like http://ghost.org - it'll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here's a link to [the Ghost website](http://ghost.org). Neat.\n\n### What about Images?\n\nImages work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:\n\n![The Ghost Logo](https://ghost.org/images/ghost.png)\n\nNot sure which image you want to use yet? That's ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:\n\n![A bowl of bananas]\n\n\n### Quoting\n\nSometimes a link isn't enough, you want to quote someone on what they've said. It was probably very wisdomous. Is wisdomous a word? Find out in a future release when we introduce spellcheck! For now - it's definitely a word.\n\n> Wisdomous - it's definitely a word.\n\n### Working with Code\n\nGot a streak of geek? We've got you covered there, too. You can write inline `<code>` blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.\n\n    .awesome-thing {\n        display: block;\n        width: 100%;\n    }\n\n### Ready for a Break? \n\nThrow 3 or more dashes down on any new line and you've got yourself a fancy new divider. Aw yeah.\n\n---\n\n### Advanced Usage\n\nThere's one fantastic secret about Markdown. If you want, you can write plain old HTML and it'll still work! Very flexible.\n\n<input type=\"text\" placeholder=\"I'm an input field!\" />\n\nThat should be enough to get you started. Have fun - and let us know what you think :)","html":"<p>You're live! Nice. We've put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at <code>&lt;your blog URL&gt;/ghost/</code>. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!</p>\n\n<h2 id=\"gettingstarted\">Getting Started</h2>\n\n<p>Ghost uses something called Markdown for writing. Essentially, it's a shorthand way to manage your post formatting as you write!</p>\n\n<p>Writing in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use <em>shortcuts</em> to <strong>style</strong> your content. For example, a list:</p>\n\n<ul>\n<li>Item number one</li>\n<li>Item number two\n<ul><li>A nested item</li></ul></li>\n<li>A final item</li>\n</ul>\n\n<p>or with numbers!</p>\n\n<ol>\n<li>Remember to buy some milk  </li>\n<li>Drink the milk  </li>\n<li>Tweet that I remembered to buy the milk, and drank it</li>\n</ol>\n\n<h3 id=\"links\">Links</h3>\n\n<p>Want to link to a source? No problem. If you paste in a URL, like <a href=\"http://ghost.org\">http://ghost.org</a> - it'll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here's a link to <a href=\"http://ghost.org\">the Ghost website</a>. Neat.</p>\n\n<h3 id=\"whataboutimages\">What about Images?</h3>\n\n<p>Images work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:</p>\n\n<p><img src=\"https://ghost.org/images/ghost.png\" alt=\"The Ghost Logo\" /></p>\n\n<p>Not sure which image you want to use yet? That's ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:</p>\n\n<h3 id=\"quoting\">Quoting</h3>\n\n<p>Sometimes a link isn't enough, you want to quote someone on what they've said. It was probably very wisdomous. Is wisdomous a word? Find out in a future release when we introduce spellcheck! For now - it's definitely a word.</p>\n\n<blockquote>\n  <p>Wisdomous - it's definitely a word.</p>\n</blockquote>\n\n<h3 id=\"workingwithcode\">Working with Code</h3>\n\n<p>Got a streak of geek? We've got you covered there, too. You can write inline <code>&lt;code&gt;</code> blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.</p>\n\n<pre><code>.awesome-thing {\n    display: block;\n    width: 100%;\n}\n</code></pre>\n\n<h3 id=\"readyforabreak\">Ready for a Break?</h3>\n\n<p>Throw 3 or more dashes down on any new line and you've got yourself a fancy new divider. Aw yeah.</p>\n\n<hr />\n\n<h3 id=\"advancedusage\">Advanced Usage</h3>\n\n<p>There's one fantastic secret about Markdown. If you want, you can write plain old HTML and it'll still work! Very flexible.</p>\n\n<p><input type=\"text\" placeholder=\"I'm an input field!\" /></p>\n\n<p>That should be enough to get you started. Have fun - and let us know what you think :)</p>","image":null,"featured":0,"page":0,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1433614737896,"created_by":1,"updated_at":1433772778456,"updated_by":1,"published_at":1433614737915,"published_by":1},{"id":3,"uuid":"8d11868e-cb25-4711-83de-eabb1bdb79b0","title":"Refocusing the MIT Climate Change Conversation","slug":"refocusing-the-mit-climate-change-conversation","markdown":"## Divestment debate overshadows direct actions\n\n**By: Daniel Rothenberg, [Alec Bogdanoff](https://twitter.com/abogdanoff), [Arthur Yip](https://twitter.com/arthurhcyip), and [Paul Kishimoto](https://paul.kishimoto.name/)**\n\n*note - this essay originally appeared in the [2015 Commencement edition of The Tech](http://tech.mit.edu/V135/N16/rothenberg.html)* \n\nThis week, the initial phase of the MIT Climate Change Conversation will conclude with the release of a committee report weighing the pros and cons of actions proposed by the MIT community. A focus of that report will be on divestment of the Institute’s endowment from fossil fuels. Without the early, critical efforts of Fossil Free MIT (FFMIT), the energetic, campus-wide discussion of MIT’s options for climate action would never have begun.\n\nBut — as current doctoral students directly engaged in climate change research and alumni of the MIT Joint Program on the Science and Policy of Global Change — we want to highlight an important part of the conversation overshadowed by the debate on divestment. The principles motivating this debate should also motivate many other actions that have been discussed less intensely. We share the divestment movement’s vision of a lower-carbon world; however, direct actions and plans to address climate change are necessary and better accord with the Institute’s global leadership in research and education.\n\nMIT’s stated mission is to lead through science and innovation. For decades, MIT academic groups have been at the forefront of research in climate, anthropogenic climate change, and the options for mitigating that change. Academics, policymakers, and citizens around the globe expect and need us to continue this work, which — some may be surprised to learn — has often been funded by the very fossil fuel industry from which some wish to divest.\n\nWhile it is true and unacceptable that several companies fund fear, uncertainty, and doubt about climate change and policy, many others see the writing on the wall. They know that change is coming, and they support MIT research in order to better understand climate change, imminent climate policies, and possible niches in a low-carbon future. And while long-term mitigation of climate change does require minimizing our dependence on fossil fuels, all credible pathways require their continued use in the near term. MIT has long embraced conscientious and productive collaborators outside academia. As a community, we should continue to expand such relationships and to bring all the major players in society’s energy transformation to our table.\n\nBeyond our external partnerships, climate scientists and policy researchers at MIT — proud of their scholarly rigor — have always upheld the responsibility to publish their findings, no matter how unpalatable those results are to sponsors or industry partners, including the fossil fuel industry. This steadfast commitment to quality and independence has earned MIT its reputation as an honest broker of sound, unvarnished, and clear-eyed technical and policy advice. This is why our faculty, alumni, and students are trusted voices in Washington, D.C. as well as capitals and boardrooms around the world. Decision-makers look to us for leadership and solutions to help tackle great challenges head-on, and they trust our counsel in a world filled with political rhetoric and polarization. Divestment is one such politically-fueled and polarizing move; we should focus on actions that better align with MIT’s unique strengths in research and education and our partnerships in these endeavors.\n\nWe strongly identify with the moral imperative at the core of the divestment movement: we must act on climate change, now! Yet knowing the problem intimately, our community cannot solely focus on symbolic gestures such as petitions and demonstrations. The radiant energy and enthusiasm focused on divestment must also be channeled towards direct actions on campus through mens et manus, invigorating innovative climate and energy actions.\n\nThe Climate Change Conversation’s Idea Bank crowdsources many such actions from the MIT community. Beyond the repetitive calls for divestment, the Idea Bank documents innovative seeds that MIT can, and should, nurture with the involvement of an even broader segment of our community. For instance, one idea calls for MIT to “lead a global problem-solving process on what to do about climate change.” This could leverage existing groups on campus such as the Climate CoLab and the Center for Global Change Science, but with a renewed focus on implementing the solutions they research. Several other ideas call for MIT to pioneer microscale climate action, such as achieving a net zero-carbon or a net energy-exporting campus. Through successes in these ventures, MIT could lead other campuses and municipalities nationwide into following in its footsteps. Both fresh and novel ideas like these and the engagement of the people behind them are the best outcomes of the Conversation.\n\nFor more than 150 years, MIT has been a trusted source of knowledge and a guide through revolutions both industrial and technological, helping transform society through groundbreaking research and education. Climate change, the great challenge of our time, is the next chapter in this history. Our community is capable of far more than just symbolic actions; we should lead the next transformation through actions that reflect our core mission: advancing knowledge and educating national and world decision-makers. Regardless of the divestment outcome, let’s re-commit the collective intellect of the MIT community to writing the chapter of society’s history in which we solve climate change.\n\n----\n\n*Daniel Rothenberg is a PhD candidate in the Program in Atmospheres, Oceans, and Climate in the Department of Earth, Atmospheric, and Planetary Sciences; Paul Kishimoto is a PhD student in Engineering Systems and a researcher with the Tsinghua-MIT China Energy & Climate Project; Alec Bogdanoff is a PhD candidate in Physical Oceanography in the MIT/Woods Hole Oceanographic Institution Joint Program in Oceanography and in the Department of Earth, Atmospheric, and Planetary Sciences; Arthur Yip is an alumni of the Joint Program on the Science and Policy of Global Change and received an S.M. from the Technology and Policy Program in 2014.*","html":"<h2 id=\"divestmentdebateovershadowsdirectactions\">Divestment debate overshadows direct actions</h2>\n\n<p><strong>By: Daniel Rothenberg, <a href=\"https://twitter.com/abogdanoff\">Alec Bogdanoff</a>, <a href=\"https://twitter.com/arthurhcyip\">Arthur Yip</a>, and <a href=\"https://paul.kishimoto.name/\">Paul Kishimoto</a></strong></p>\n\n<p><em>note - this essay originally appeared in the <a href=\"http://tech.mit.edu/V135/N16/rothenberg.html\">2015 Commencement edition of The Tech</a></em> </p>\n\n<p>This week, the initial phase of the MIT Climate Change Conversation will conclude with the release of a committee report weighing the pros and cons of actions proposed by the MIT community. A focus of that report will be on divestment of the Institute’s endowment from fossil fuels. Without the early, critical efforts of Fossil Free MIT (FFMIT), the energetic, campus-wide discussion of MIT’s options for climate action would never have begun.</p>\n\n<p>But — as current doctoral students directly engaged in climate change research and alumni of the MIT Joint Program on the Science and Policy of Global Change — we want to highlight an important part of the conversation overshadowed by the debate on divestment. The principles motivating this debate should also motivate many other actions that have been discussed less intensely. We share the divestment movement’s vision of a lower-carbon world; however, direct actions and plans to address climate change are necessary and better accord with the Institute’s global leadership in research and education.</p>\n\n<p>MIT’s stated mission is to lead through science and innovation. For decades, MIT academic groups have been at the forefront of research in climate, anthropogenic climate change, and the options for mitigating that change. Academics, policymakers, and citizens around the globe expect and need us to continue this work, which — some may be surprised to learn — has often been funded by the very fossil fuel industry from which some wish to divest.</p>\n\n<p>While it is true and unacceptable that several companies fund fear, uncertainty, and doubt about climate change and policy, many others see the writing on the wall. They know that change is coming, and they support MIT research in order to better understand climate change, imminent climate policies, and possible niches in a low-carbon future. And while long-term mitigation of climate change does require minimizing our dependence on fossil fuels, all credible pathways require their continued use in the near term. MIT has long embraced conscientious and productive collaborators outside academia. As a community, we should continue to expand such relationships and to bring all the major players in society’s energy transformation to our table.</p>\n\n<p>Beyond our external partnerships, climate scientists and policy researchers at MIT — proud of their scholarly rigor — have always upheld the responsibility to publish their findings, no matter how unpalatable those results are to sponsors or industry partners, including the fossil fuel industry. This steadfast commitment to quality and independence has earned MIT its reputation as an honest broker of sound, unvarnished, and clear-eyed technical and policy advice. This is why our faculty, alumni, and students are trusted voices in Washington, D.C. as well as capitals and boardrooms around the world. Decision-makers look to us for leadership and solutions to help tackle great challenges head-on, and they trust our counsel in a world filled with political rhetoric and polarization. Divestment is one such politically-fueled and polarizing move; we should focus on actions that better align with MIT’s unique strengths in research and education and our partnerships in these endeavors.</p>\n\n<p>We strongly identify with the moral imperative at the core of the divestment movement: we must act on climate change, now! Yet knowing the problem intimately, our community cannot solely focus on symbolic gestures such as petitions and demonstrations. The radiant energy and enthusiasm focused on divestment must also be channeled towards direct actions on campus through mens et manus, invigorating innovative climate and energy actions.</p>\n\n<p>The Climate Change Conversation’s Idea Bank crowdsources many such actions from the MIT community. Beyond the repetitive calls for divestment, the Idea Bank documents innovative seeds that MIT can, and should, nurture with the involvement of an even broader segment of our community. For instance, one idea calls for MIT to “lead a global problem-solving process on what to do about climate change.” This could leverage existing groups on campus such as the Climate CoLab and the Center for Global Change Science, but with a renewed focus on implementing the solutions they research. Several other ideas call for MIT to pioneer microscale climate action, such as achieving a net zero-carbon or a net energy-exporting campus. Through successes in these ventures, MIT could lead other campuses and municipalities nationwide into following in its footsteps. Both fresh and novel ideas like these and the engagement of the people behind them are the best outcomes of the Conversation.</p>\n\n<p>For more than 150 years, MIT has been a trusted source of knowledge and a guide through revolutions both industrial and technological, helping transform society through groundbreaking research and education. Climate change, the great challenge of our time, is the next chapter in this history. Our community is capable of far more than just symbolic actions; we should lead the next transformation through actions that reflect our core mission: advancing knowledge and educating national and world decision-makers. Regardless of the divestment outcome, let’s re-commit the collective intellect of the MIT community to writing the chapter of society’s history in which we solve climate change.</p>\n\n<hr />\n\n<p><em>Daniel Rothenberg is a PhD candidate in the Program in Atmospheres, Oceans, and Climate in the Department of Earth, Atmospheric, and Planetary Sciences; Paul Kishimoto is a PhD student in Engineering Systems and a researcher with the Tsinghua-MIT China Energy &amp; Climate Project; Alec Bogdanoff is a PhD candidate in Physical Oceanography in the MIT/Woods Hole Oceanographic Institution Joint Program in Oceanography and in the Department of Earth, Atmospheric, and Planetary Sciences; Arthur Yip is an alumni of the Joint Program on the Science and Policy of Global Change and received an S.M. from the Technology and Policy Program in 2014.</em></p>","image":"https://pbs.twimg.com/profile_images/540610525676052480/sD5lLKF5_400x400.jpeg","featured":1,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":"","author_id":1,"created_at":1433769087233,"created_by":1,"updated_at":1433771589132,"updated_by":1,"published_at":1433769900000,"published_by":1},{"id":5,"uuid":"16d91321-b96f-4f08-965d-e8bc4c6782df","title":"Projects","slug":"projects","markdown":"(A gallery of my projects is currently under construction. For the meantime, feel free to peruse my [public code on github](https://github.com/darothen)!)","html":"<p>(A gallery of my projects is currently under construction. For the meantime, feel free to peruse my <a href=\"https://github.com/darothen\">public code on github</a>!)</p>","image":null,"featured":0,"page":1,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1434068381040,"created_by":1,"updated_at":1435944433205,"updated_by":1,"published_at":1434068381041,"published_by":1},{"id":6,"uuid":"0542c90d-1811-4d43-bbc3-5b93e687f4e0","title":"Simple Ray Tracer in NumbaPro-CUDA","slug":"simple-ray-tracer-in-numbapro-cuda","markdown":"For a long time, I've been looking for a good application of CUDA/GPGPU programming to some of the basic analysis I do in my research. Unfortunately, there really hasn't ever been any low-hanging fruit. That coupled with my desire to avoid pure C-programming at all costs was an ideal combination for avoiding learning the CUDA basics!\n\nThat all changed last week and I decided to dive into things by working through [CUDA by Example]. As an added bonus, I decided to port everything I learned to Python using [NumbaPro](http://docs.continuum.io/numbapro/), which enables extensions for very easily compiling CUDA kernels. \n\nOne of the really neat little projects in [CUDA by Example] is a simple ray tracer viewing a scene with random spheres:\n\n![Random spheres!](/content/images/2015/06/ray_C.png)\n\nThe thing is *bleeding* fast on a GPU, but is so unbearably slow on a CPU (using a naive algorithm) that it's not worth attempting[^1]. It turns out, it's nearly as fast using NumbaPro and its CUDA/GPU extensions, and just as easy to write.\n\n### Porting to Python\n\nWe start with a simple data structure for encapsulating information for each of our spheres. The easiest way to bind such a structure from the CPU->GPU in Python is a NumPy record array using a user-defined datatype:\n\n```language-python\nSphere = np.dtype([\n    # RGB color values (floats from [0, 1])\n    ('r', 'f4'),  ('g', 'f4'), ('b', 'f4'), \n    # sphere radius \n    ('radius', 'f4'),\n    # sphere (x, y, z) coordinates \n    ('x', 'f4'),  ('y', 'f4'), ('z', 'f4'),], align=True) \nSphere_t = numbapro.from_dtype(Sphere)\n```\n\nThe only fancy thing we have to do here is bind our `Sphere` type to something Numba recognizes via the last line; the rest of the Sphere data should be self-explanatory. \n\nTwo helper functions will come in handy in our calculation. First, it would be nice to have a function that computes whether or not a ray starting at (x, y) actually hits a given sphere. We write a `hit()` method compute this:\n\n```language-python\ndef hit(ox, oy, sph):\n    \"\"\" Compute whether a ray parallel to the z-axis originating at \n    (ox, oy, INF) will intersect a given sphere; if so, return the \n    distance to the surface of the sphere.\n    \"\"\"\n    dx = ox - sph.x\n    dy = oy - sph.y\n    rad = sph.radius\n    if ( dx*dx + dy*dy < rad*rad ):\n        dz = sqrt( rad*rad - dx*dx - dy*dy )\n        return dz + sph.z\n    else:\n        return -INF\n```\n\nNote that we use an attribute syntax to get `Sphere` data, rather than a `dict`-like lookup. This is an idiosyncrasy of Numba. To turn this into a function that runs on the GPU, we annotate it with a decorator from NumbaPro, `@cuda.jit(restype=float32, argtypes=[float32, float32, Sphere_t], device=True, inline=True)`. This just tells NumbaPro to create a function which returns a float given three inputs: two floats and one `Sphere`. We then tell it to compile this function to run specially on the GPU.\n\nNow, we need a function that iterates over *all* of the spheres to compute potential intersections at each observer pixel. This is the core 'kernel' which we'll run on the GPU, and it would look something like this:\n\n``` language-python\n@cuda.jit(argtypes=(Sphere_t[:], int16[:,:,:]))\ndef kernel(spheres, bitmap):\n    \n    x, y = cuda.grid(2) # alias for threadIdx.x + ( blockIdx.x * blockDim.x ),\n                        #           threadIdx.y + ( blockIdx.y * blockDim.y )\n    # shift the grid to [-DIM/2, DIM/2]\n    ox = x - DIM/2\n    oy = y - DIM/2\n\n    r = 0. \n    g = 0.\n    b = 0.\n    maxz = -INF\n\n    i = 0 # emulate a C-style for-loop, exposing the idx increment logic\n    while (i < SPHERES):\n        t = hit(ox, oy, spheres[i])\n        rad = spheres[i].radius\n\n        if (t > maxz):\n            dz = t - spheres[i].z # t = dz + z; inverting hit() result\n            n = dz / sqrt( rad*rad )\n            fscale = n # shades the color to be darker as we recede from \n                       # the edge of the cube circumscribing the sphere\n\n            r = spheres[i].r*fscale\n            g = spheres[i].g*fscale\n            b = spheres[i].b*fscale\n            maxz = t\n        i += 1\n\n    # Save the RGBA value for this particular pixel\n    bitmap[x,y,0] = int(r*255.)\n    bitmap[x,y,1] = int(g*255.)\n    bitmap[x,y,2] = int(b*255.)\n    bitmap[x,y,3] = 255\n```\n\nThere's nothing fancy going on here. NumbaPro gives us an alias (`cuda.grid()`) to the prototypical thread-index lookup mathematics we'd normally undertake. The way we've designed the kernel, a different thread on the GPU will compute the ray trace for each observer pixel in our image. It's virtually identically to the logic we'd use in pure CUDA. One difference is that we can take advantage of the fact our image data-structure is a 2D array (ignoring the RGBA dimension), and directly associate threads with a particular address in that array, rather than use linear offsets.\n\nJust like in pure CUDA, we need to manage data transfers between host and device. For instance, we can initialize some device memory for working with our resulting image and storing our Spheres:\n\n``` language-python\n    # Create a container for the pixel RGBA information of our image\n    bitmap = np.zeros([DIM, DIM, 4], dtype=np.int16)\n   \n    # Copy to device memory \n    d_bitmap = cuda.to_device(bitmap)\n    # Create empty container for our Sphere data on device\n    d_spheres = cuda.device_array(SPHERES, dtype=Sphere_t)\n\n    # Create an empty container of spheres on host\n    temp_spheres = np.empty(SPHERES, dtype=Sphere_t)\n    # ... sphere creation steps ...\n    # Copy the sphere data to the device\n    cuda.to_device(temp_spheres, to=d_spheres) \n```\n\nThe command for `bitmap` is similar to a `malloc` and assignment all in one. To initialize `d_bitmap` on the device, we can just copy over `bitmap`. Then we call a command similar to `cudaMalloc` to ready an array to contain our sphere data. Finally, we initialize `temp_spheres` on the host like using `malloc`,  populate it, and explicitly copy it to device into the memory already assigned for it.\n\nAt this point, the device has all the data we need to run the calculation, so we do can go ahead and call the `kernel`:\n\n``` language-python\n    grids = (DIM/16, DIM/16)\n    threads = (16, 16)\n\n    # Execute the kernel\n    kernel[grids, threads](d_spheres, d_bitmap)\n\n    # Copy the result from the kernel ordering the ray tracing back to host\n    bitmap = d_bitmap.copy_to_host()\n```\n\nIn the first two commands, we set up a grid of (DIM/16 x DIM/16) blocks, each with an array of (16 x 16) threads. If DIM is a reasonable power of 2, this will totally cover the image with one thread for each pixel. On my GeForce GTX 750ti, I can successfully compute images with DIM <= 2**14 before I run out of memory[^2]. Executing the kernel with this grid configuration is just like using the `<<< >>>` notation in CUDA, except we use brackets here and call the function with its arguments like normal. In the final step, we copy the resulting calculation from disk memory back to the host.\n\nThen, we can render our image using matplotlib:\n\n``` language-python\n    bitmap = np.transpose(bitmap/255., (1, 0, 2)) # swap image's x-y axes\n    plt.imshow(bitmap)\n```\n\nand voila!\n\n![Spheres in Python rendered via CUDA!](/content/images/2015/06/ray_py-1.png)\n\nAmazingly, the NumbaPro-generated CUDA solution performs within a factor of 2 against the original CUDA implementation, including memory transfers. That's pretty amazing considering it's doing everything automatically!\n\nFull code for this toy project is available as a [gist](https://gist.github.com/darothen/f53bb3e40edbceb38904).\n\n---\n\n<!--Footnotes-->\n[^1]: You can see in the full code that we compute vertical rays from +/- scene Z-infinity for each pixel. We could easily improve on this by pre-computing the x-y coverage of the sphere ensemble and only compute rays for pixels we *know* will intercept a sphere, and then only sample the top \"layer\" of spheres by inspecting their z-position and radii.\n[^2]: And this is just using a simple algorithm where we compute the whole image simultaneously! We could probably chunk it and compute even larger scenes.\n\n<!--Bookmarks-->\n[CUDA by Example]: http://www.amazon.com/CUDA-Example-Introduction-General-Purpose-Programming/dp/0131387685","html":"<p>For a long time, I've been looking for a good application of CUDA/GPGPU programming to some of the basic analysis I do in my research. Unfortunately, there really hasn't ever been any low-hanging fruit. That coupled with my desire to avoid pure C-programming at all costs was an ideal combination for avoiding learning the CUDA basics!</p>\n\n<p>That all changed last week and I decided to dive into things by working through <a href=\"http://www.amazon.com/CUDA-Example-Introduction-General-Purpose-Programming/dp/0131387685\">CUDA by Example</a>. As an added bonus, I decided to port everything I learned to Python using <a href=\"http://docs.continuum.io/numbapro/\">NumbaPro</a>, which enables extensions for very easily compiling CUDA kernels. </p>\n\n<p>One of the really neat little projects in <a href=\"http://www.amazon.com/CUDA-Example-Introduction-General-Purpose-Programming/dp/0131387685\">CUDA by Example</a> is a simple ray tracer viewing a scene with random spheres:</p>\n\n<p><img src=\"/content/images/2015/06/ray_C.png\" alt=\"Random spheres!\" /></p>\n\n<p>The thing is <em>bleeding</em> fast on a GPU, but is so unbearably slow on a CPU (using a naive algorithm) that it's not worth attempting<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup>. It turns out, it's nearly as fast using NumbaPro and its CUDA/GPU extensions, and just as easy to write.</p>\n\n<h3 id=\"portingtopython\">Porting to Python</h3>\n\n<p>We start with a simple data structure for encapsulating information for each of our spheres. The easiest way to bind such a structure from the CPU->GPU in Python is a NumPy record array using a user-defined datatype:</p>\n\n<pre><code class=\"language-python\">Sphere = np.dtype([  \n    # RGB color values (floats from [0, 1])\n    ('r', 'f4'),  ('g', 'f4'), ('b', 'f4'), \n    # sphere radius \n    ('radius', 'f4'),\n    # sphere (x, y, z) coordinates \n    ('x', 'f4'),  ('y', 'f4'), ('z', 'f4'),], align=True) \nSphere_t = numbapro.from_dtype(Sphere)  \n</code></pre>\n\n<p>The only fancy thing we have to do here is bind our <code>Sphere</code> type to something Numba recognizes via the last line; the rest of the Sphere data should be self-explanatory. </p>\n\n<p>Two helper functions will come in handy in our calculation. First, it would be nice to have a function that computes whether or not a ray starting at (x, y) actually hits a given sphere. We write a <code>hit()</code> method compute this:</p>\n\n<pre><code class=\"language-python\">def hit(ox, oy, sph):  \n    \"\"\" Compute whether a ray parallel to the z-axis originating at \n    (ox, oy, INF) will intersect a given sphere; if so, return the \n    distance to the surface of the sphere.\n    \"\"\"\n    dx = ox - sph.x\n    dy = oy - sph.y\n    rad = sph.radius\n    if ( dx*dx + dy*dy &lt; rad*rad ):\n        dz = sqrt( rad*rad - dx*dx - dy*dy )\n        return dz + sph.z\n    else:\n        return -INF\n</code></pre>\n\n<p>Note that we use an attribute syntax to get <code>Sphere</code> data, rather than a <code>dict</code>-like lookup. This is an idiosyncrasy of Numba. To turn this into a function that runs on the GPU, we annotate it with a decorator from NumbaPro, <code>@cuda.jit(restype=float32, argtypes=[float32, float32, Sphere_t], device=True, inline=True)</code>. This just tells NumbaPro to create a function which returns a float given three inputs: two floats and one <code>Sphere</code>. We then tell it to compile this function to run specially on the GPU.</p>\n\n<p>Now, we need a function that iterates over <em>all</em> of the spheres to compute potential intersections at each observer pixel. This is the core 'kernel' which we'll run on the GPU, and it would look something like this:</p>\n\n<pre><code class=\"language- language-python\">@cuda.jit(argtypes=(Sphere_t[:], int16[:,:,:]))\ndef kernel(spheres, bitmap):\n\n    x, y = cuda.grid(2) # alias for threadIdx.x + ( blockIdx.x * blockDim.x ),\n                        #           threadIdx.y + ( blockIdx.y * blockDim.y )\n    # shift the grid to [-DIM/2, DIM/2]\n    ox = x - DIM/2\n    oy = y - DIM/2\n\n    r = 0. \n    g = 0.\n    b = 0.\n    maxz = -INF\n\n    i = 0 # emulate a C-style for-loop, exposing the idx increment logic\n    while (i &lt; SPHERES):\n        t = hit(ox, oy, spheres[i])\n        rad = spheres[i].radius\n\n        if (t &gt; maxz):\n            dz = t - spheres[i].z # t = dz + z; inverting hit() result\n            n = dz / sqrt( rad*rad )\n            fscale = n # shades the color to be darker as we recede from \n                       # the edge of the cube circumscribing the sphere\n\n            r = spheres[i].r*fscale\n            g = spheres[i].g*fscale\n            b = spheres[i].b*fscale\n            maxz = t\n        i += 1\n\n    # Save the RGBA value for this particular pixel\n    bitmap[x,y,0] = int(r*255.)\n    bitmap[x,y,1] = int(g*255.)\n    bitmap[x,y,2] = int(b*255.)\n    bitmap[x,y,3] = 255\n</code></pre>\n\n<p>There's nothing fancy going on here. NumbaPro gives us an alias (<code>cuda.grid()</code>) to the prototypical thread-index lookup mathematics we'd normally undertake. The way we've designed the kernel, a different thread on the GPU will compute the ray trace for each observer pixel in our image. It's virtually identically to the logic we'd use in pure CUDA. One difference is that we can take advantage of the fact our image data-structure is a 2D array (ignoring the RGBA dimension), and directly associate threads with a particular address in that array, rather than use linear offsets.</p>\n\n<p>Just like in pure CUDA, we need to manage data transfers between host and device. For instance, we can initialize some device memory for working with our resulting image and storing our Spheres:</p>\n\n<pre><code class=\"language- language-python\">    # Create a container for the pixel RGBA information of our image\n    bitmap = np.zeros([DIM, DIM, 4], dtype=np.int16)\n\n    # Copy to device memory \n    d_bitmap = cuda.to_device(bitmap)\n    # Create empty container for our Sphere data on device\n    d_spheres = cuda.device_array(SPHERES, dtype=Sphere_t)\n\n    # Create an empty container of spheres on host\n    temp_spheres = np.empty(SPHERES, dtype=Sphere_t)\n    # ... sphere creation steps ...\n    # Copy the sphere data to the device\n    cuda.to_device(temp_spheres, to=d_spheres) \n</code></pre>\n\n<p>The command for <code>bitmap</code> is similar to a <code>malloc</code> and assignment all in one. To initialize <code>d_bitmap</code> on the device, we can just copy over <code>bitmap</code>. Then we call a command similar to <code>cudaMalloc</code> to ready an array to contain our sphere data. Finally, we initialize <code>temp_spheres</code> on the host like using <code>malloc</code>,  populate it, and explicitly copy it to device into the memory already assigned for it.</p>\n\n<p>At this point, the device has all the data we need to run the calculation, so we do can go ahead and call the <code>kernel</code>:</p>\n\n<pre><code class=\"language- language-python\">    grids = (DIM/16, DIM/16)\n    threads = (16, 16)\n\n    # Execute the kernel\n    kernel[grids, threads](d_spheres, d_bitmap)\n\n    # Copy the result from the kernel ordering the ray tracing back to host\n    bitmap = d_bitmap.copy_to_host()\n</code></pre>\n\n<p>In the first two commands, we set up a grid of (DIM/16 x DIM/16) blocks, each with an array of (16 x 16) threads. If DIM is a reasonable power of 2, this will totally cover the image with one thread for each pixel. On my GeForce GTX 750ti, I can successfully compute images with DIM &lt;= 2**14 before I run out of memory<sup id=\"fnref:2\"><a href=\"#fn:2\" rel=\"footnote\">2</a></sup>. Executing the kernel with this grid configuration is just like using the <code>&lt;&lt;&lt; &gt;&gt;&gt;</code> notation in CUDA, except we use brackets here and call the function with its arguments like normal. In the final step, we copy the resulting calculation from disk memory back to the host.</p>\n\n<p>Then, we can render our image using matplotlib:</p>\n\n<pre><code class=\"language- language-python\">    bitmap = np.transpose(bitmap/255., (1, 0, 2)) # swap image's x-y axes\n    plt.imshow(bitmap)\n</code></pre>\n\n<p>and voila!</p>\n\n<p><img src=\"/content/images/2015/06/ray_py-1.png\" alt=\"Spheres in Python rendered via CUDA!\" /></p>\n\n<p>Amazingly, the NumbaPro-generated CUDA solution performs within a factor of 2 against the original CUDA implementation, including memory transfers. That's pretty amazing considering it's doing everything automatically!</p>\n\n<p>Full code for this toy project is available as a <a href=\"https://gist.github.com/darothen/f53bb3e40edbceb38904\">gist</a>.</p>\n\n<hr />\n\n<!--Footnotes-->  \n\n<div class=\"footnotes\"><ol><li class=\"footnote\" id=\"fn:1\"><p>You can see in the full code that we compute vertical rays from +/- scene Z-infinity for each pixel. We could easily improve on this by pre-computing the x-y coverage of the sphere ensemble and only compute rays for pixels we <em>know</em> will intercept a sphere, and then only sample the top \"layer\" of spheres by inspecting their z-position and radii. <a href=\"#fnref:1\" title=\"return to article\">↩</a></p></li>\n<li class=\"footnote\" id=\"fn:2\"><p>And this is just using a simple algorithm where we compute the whole image simultaneously! We could probably chunk it and compute even larger scenes. <a href=\"#fnref:2\" title=\"return to article\">↩</a></p></li></ol></div>\n\n<!--Bookmarks-->  ","image":"/content/images/2015/06/ray_C-1.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"","meta_description":"","author_id":1,"created_at":1434069725620,"created_by":1,"updated_at":1435944376630,"updated_by":1,"published_at":1434074863149,"published_by":1},{"id":8,"uuid":"e47b4afe-79d4-47c4-b883-9b3939dab88a","title":"About","slug":"about","markdown":"I'm a doctoral candidate studying meteorology, clouds, and climate science in the [Program in Atmospheres, Oceans, and Climate](http://eaps-www.mit.edu/paoc/) at [MIT](http://www.mit.edu). I'm also affiliated with several other program and academic groups at MIT, including the [Joint Program on the Science and Policy of Global Change](http://globalchange.mit.edu/) and the [Science Policy Initiative](http://www.mitspi.org/). \n\nI'm a Pythonista, and I use modern code and techniques to build tools for more efficiently and thoroughly studying all sorts of interesting research problems.\n\nThis blog catalogs my thoughts and opinions on things, and highlights interesting analyses or tools that I use in my research and work. \n\nIf you're interested in the details of my research and professional activities, you can find my current CV [here](https://github.com/darothen/vita/raw/master/compiled/vita.pdf). Or you could check me and my work out on [twitter](http://twitter.com/danrothenberg), [GitHub](http://github.com/darothen), [Authorea](https://www.authorea.com/users/4384), or [Researchgate](https://www.researchgate.net/profile/Daniel_Rothenberg).\n\n---\n\n<small>This nifty blog / homepage was built on top of [ghost](https://ghost.org/) by [Matt Rothenberg](http://mattrothenberg.com/about) ([@mattrothenberg](http://www.twitter.com/mattrothenberg)).</small>","html":"<p>I'm a doctoral candidate studying meteorology, clouds, and climate science in the <a href=\"http://eaps-www.mit.edu/paoc/\">Program in Atmospheres, Oceans, and Climate</a> at <a href=\"http://www.mit.edu\">MIT</a>. I'm also affiliated with several other program and academic groups at MIT, including the <a href=\"http://globalchange.mit.edu/\">Joint Program on the Science and Policy of Global Change</a> and the <a href=\"http://www.mitspi.org/\">Science Policy Initiative</a>. </p>\n\n<p>I'm a Pythonista, and I use modern code and techniques to build tools for more efficiently and thoroughly studying all sorts of interesting research problems.</p>\n\n<p>This blog catalogs my thoughts and opinions on things, and highlights interesting analyses or tools that I use in my research and work. </p>\n\n<p>If you're interested in the details of my research and professional activities, you can find my current CV <a href=\"https://github.com/darothen/vita/raw/master/compiled/vita.pdf\">here</a>. Or you could check me and my work out on <a href=\"http://twitter.com/danrothenberg\">twitter</a>, <a href=\"http://github.com/darothen\">GitHub</a>, <a href=\"https://www.authorea.com/users/4384\">Authorea</a>, or <a href=\"https://www.researchgate.net/profile/Daniel_Rothenberg\">Researchgate</a>.</p>\n\n<hr />\n\n<p><small>This nifty blog / homepage was built on top of <a href=\"https://ghost.org/\">ghost</a> by <a href=\"http://mattrothenberg.com/about\">Matt Rothenberg</a> (<a href=\"http://www.twitter.com/mattrothenberg\">@mattrothenberg</a>).</small></p>","image":null,"featured":0,"page":1,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1434990046674,"created_by":1,"updated_at":1434991665730,"updated_by":1,"published_at":1434990051028,"published_by":1},{"id":9,"uuid":"4422d1c9-2a3d-4beb-9df5-244d268ae8f0","title":"Git Ignorin'","slug":"git-ignorin","markdown":"It gets really old having to create a site-specific `.gitignore` anytime I start a new project. It's especially troublesome since I tend to access the same repository when it's mounted on different filesystems, creating all sorts of superfluous, useless files (I'm talking about you, **.DS_Store**). Luckily, [gitignore.io](https://www.gitignore.io) has your back, and can quickly generate lists of ignorable files from many different operating systems, editors, and programming languages. Very useful!\n\n**OSX .gitignore**\n``` bash\n### OSX ###\n.DS_Store\n.AppleDouble\n.LSOverride\n\n# Icon must end with two \\r\nIcon\n\n\n# Thumbnails\n._*\n\n# Files that might appear in the root of a volume\n.DocumentRevisions-V100\n.fseventsd\n.Spotlight-V100\n.TemporaryItems\n.Trashes\n.VolumeIcon.icns\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk\n```","html":"<p>It gets really old having to create a site-specific <code>.gitignore</code> anytime I start a new project. It's especially troublesome since I tend to access the same repository when it's mounted on different filesystems, creating all sorts of superfluous, useless files (I'm talking about you, <strong>.DS_Store</strong>). Luckily, <a href=\"https://www.gitignore.io\">gitignore.io</a> has your back, and can quickly generate lists of ignorable files from many different operating systems, editors, and programming languages. Very useful!</p>\n\n<p><strong>OSX .gitignore</strong></p>\n\n<pre><code class=\"language- bash\">### OSX ###\n.DS_Store\n.AppleDouble\n.LSOverride\n\n# Icon must end with two \\r\nIcon\n\n\n# Thumbnails\n._*\n\n# Files that might appear in the root of a volume\n.DocumentRevisions-V100\n.fseventsd\n.Spotlight-V100\n.TemporaryItems\n.Trashes\n.VolumeIcon.icns\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder  \nTemporary Items  \n.apdisk\n</code></pre>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1435327449430,"created_by":1,"updated_at":1435944320913,"updated_by":1,"published_at":1435327625346,"published_by":1},{"id":10,"uuid":"d45535db-a293-417a-9c1d-5ea89ef607df","title":"Plotting HYCOM/RTOFS SST data in Python","slug":"plotting-hycomrtofs-sst-data-in-python","markdown":"\nBased on [this notebook](https://gist.github.com/darothen/84ae9a29154389fe45a5), which highlights some basics on reading in RTOFS/netCDF output into Python, manipulating that data, and plotting it. For additional examples, [Filipe Fernandes has a great example of similar operations on his blog](https://ocefpaf.github.io/python4oceanographers/blog/2014/12/29/iris_ocean_models/).\n\n\n```python\n    import netCDF4 as nc\n    import numpy as np\n    \n    %matplotlib inline\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    sns.set(style=\"ticks\")\n```\n\nDownload some RTOFS global output. It's a rather large file, so be sure to comment out this command once it's already downloaded!\n\n\n``` language-bash\n#!curl -O ftp://ftpprd.ncep.noaa.gov/pub/data/nccf/com/rtofs/prod/rtofs.20150701/rtofs_glo_2ds_f001_1hrly_prog.nc\n```\n\nFor starters, let's read in the data using the Unidate `netCDF4` module. This module gives very low-level access to the netCDF file - basically just its raw contents and metadata. We load the file directly into memory using the `Dataset` type, and print it to give an overview of its contents.\n\n``` language-python\n    fn = \"rtofs_glo_2ds_f001_1hrly_prog.nc\"\n    data = nc.Dataset(fn)\n    print data\n``` \n\n    <type 'netCDF4.Dataset'>\n    root group (NETCDF3_CLASSIC data model, file format UNDEFINED):\n        Conventions: CF-1.0\n        title: HYCOM ATLb2.00\n        institution: National Centers for Environmental Prediction\n        source: HYCOM archive file\n        experiment: 90.9\n        history: archv2ncdf2d\n        dimensions(sizes): MT(1), Y(3298), X(4500), Layer(1)\n        variables(dimensions): float64 \u001b[4mMT\u001b[0m(MT), float64 \u001b[4mDate\u001b[0m(MT), int32 \u001b[4mLayer\u001b[0m(Layer), int32 \u001b[4mY\u001b[0m(Y), int32 \u001b[4mX\u001b[0m(X), float32 \u001b[4mLatitude\u001b[0m(Y,X), float32 \u001b[4mLongitude\u001b[0m(Y,X), float32 \u001b[4mu_velocity\u001b[0m(MT,Layer,Y,X), float32 \u001b[4mv_velocity\u001b[0m(MT,Layer,Y,X), float32 \u001b[4msst\u001b[0m(MT,Y,X), float32 \u001b[4msss\u001b[0m(MT,Y,X), float32 \u001b[4mlayer_density\u001b[0m(MT,Layer,Y,X)\n        groups: \n  \n\n\nEach `Dataset` object contains a dict-like interface for accessing variables, which can be selected by their *var_name* from the original netCDF file. Let's select the SST data and inspect it in more detail.\n\n\n``` language-python\n    sst = data.variables['sst']\n    print sst\n```\n\n    <type 'netCDF4.Variable'>\n    float32 sst(MT, Y, X)\n        coordinates: Longitude Latitude Date\n        standard_name: sea_surface_temperature\n        units: degC\n        _FillValue: 1.26765e+30\n        valid_range: [ -3.58215308  34.7584877 ]\n        long_name:  sea surf. temp.   [90.9H]\n    unlimited dimensions: MT\n    current shape = (1, 3298, 4500)\n    filling off\n    \n\n\nThis gives us a quick overview of the sst data. It's a 3-dimensional dataset (time, latitude, and longitude). Furthermore, from the inspection of the full dataset, we can see that the latitude and longitude coordinates are actually aliases for a complex, 2D latitude-longitude system underpinning the model coordinate systems. \n\n---\n\nNote that we can use standard netCDF terminal commands to also inspect the contents of the dataset:\n\n\n``` language-bash\n    !ncdump -h {fn}\n```\n\n    netcdf rtofs_glo_2ds_f001_1hrly_prog {\n    dimensions:\n    \tMT = UNLIMITED ; // (1 currently)\n    \tY = 3298 ;\n    \tX = 4500 ;\n    \tLayer = 1 ;\n    variables:\n    \tdouble MT(MT) ;\n    \t\tMT:long_name = \"time\" ;\n    \t\tMT:units = \"days since 1900-12-31 00:00:00\" ;\n    \t\tMT:calendar = \"standard\" ;\n    \t\tMT:axis = \"T\" ;\n    \tdouble Date(MT) ;\n    \t\tDate:long_name = \"date\" ;\n    \t\tDate:units = \"day as %Y%m%d.%f\" ;\n    \t\tDate:C_format = \"%13.4f\" ;\n    \t\tDate:FORTRAN_format = \"(f13.4)\" ;\n    \tint Layer(Layer) ;\n    \t\tLayer:units = \"layer\" ;\n    \t\tLayer:positive = \"down\" ;\n    \t\tLayer:axis = \"Z\" ;\n    \tint Y(Y) ;\n    \t\tY:point_spacing = \"even\" ;\n    \t\tY:axis = \"Y\" ;\n    \tint X(X) ;\n    \t\tX:point_spacing = \"even\" ;\n    \t\tX:axis = \"X\" ;\n    \tfloat Latitude(Y, X) ;\n    \t\tLatitude:standard_name = \"latitude\" ;\n    \t\tLatitude:units = \"degrees_north\" ;\n    \tfloat Longitude(Y, X) ;\n    \t\tLongitude:standard_name = \"longitude\" ;\n    \t\tLongitude:units = \"degrees_east\" ;\n    \t\tLongitude:modulo = \"360 degrees\" ;\n    \tfloat u_velocity(MT, Layer, Y, X) ;\n    \t\tu_velocity:coordinates = \"Longitude Latitude Date\" ;\n    \t\tu_velocity:standard_name = \"eastward_sea_water_velocity\" ;\n    \t\tu_velocity:units = \"m/s\" ;\n    \t\tu_velocity:_FillValue = 1.267651e+30f ;\n    \t\tu_velocity:valid_range = -2.127099f, 2.834078f ;\n    \t\tu_velocity:long_name = \" u-veloc. [90.9H]\" ;\n    \tfloat v_velocity(MT, Layer, Y, X) ;\n    \t\tv_velocity:coordinates = \"Longitude Latitude Date\" ;\n    \t\tv_velocity:standard_name = \"northward_sea_water_velocity\" ;\n    \t\tv_velocity:units = \"m/s\" ;\n    \t\tv_velocity:_FillValue = 1.267651e+30f ;\n    \t\tv_velocity:valid_range = -2.466692f, 2.390137f ;\n    \t\tv_velocity:long_name = \" v-veloc. [90.9H]\" ;\n    \tfloat sst(MT, Y, X) ;\n    \t\tsst:coordinates = \"Longitude Latitude Date\" ;\n    \t\tsst:standard_name = \"sea_surface_temperature\" ;\n    \t\tsst:units = \"degC\" ;\n    \t\tsst:_FillValue = 1.267651e+30f ;\n    \t\tsst:valid_range = -3.582153f, 34.75849f ;\n    \t\tsst:long_name = \" sea surf. temp.   [90.9H]\" ;\n    \tfloat sss(MT, Y, X) ;\n    \t\tsss:coordinates = \"Longitude Latitude Date\" ;\n    \t\tsss:standard_name = \"sea_surface_salinity\" ;\n    \t\tsss:units = \"psu\" ;\n    \t\tsss:_FillValue = 1.267651e+30f ;\n    \t\tsss:valid_range = 0.2699257f, 40.10468f ;\n    \t\tsss:long_name = \"sea surf. salnity  [90.9H]\" ;\n    \tfloat layer_density(MT, Layer, Y, X) ;\n    \t\tlayer_density:coordinates = \"Longitude Latitude Date\" ;\n    \t\tlayer_density:standard_name = \"sea_water_potential_density\" ;\n    \t\tlayer_density:units = \"sigma\" ;\n    \t\tlayer_density:_FillValue = 1.267651e+30f ;\n    \t\tlayer_density:valid_range = 0.f, 0.f ;\n    \t\tlayer_density:long_name = \" density [90.9H]\" ;\n    \n    // global attributes:\n    \t\t:Conventions = \"CF-1.0\" ;\n    \t\t:title = \"HYCOM ATLb2.00\" ;\n    \t\t:institution = \"National Centers for Environmental Prediction\" ;\n    \t\t:source = \"HYCOM archive file\" ;\n    \t\t:experiment = \"90.9\" ;\n    \t\t:history = \"archv2ncdf2d\" ;\n    }\n\n\n---\n\nAnother useful package for reading in netCDF or other structured datasets is [`xray`](http://xray.readthedocs.org/en/stable/). `xray` automatically labels coordinate axes and gives a `pandas`-like interface to manipulating data. For instance, here is an example of selecting the sst data from the netCDF file using `xray`, and plotting the distribution of temperature values:\n\n\n``` language-python\n    import xray\n    ds = xray.open_dataset(fn, decode_times=True)\n    sst = ds.sst.values.ravel()\n    sst_masked = sst[~np.isnan(sst)]\n    \n    ## Masking a numpy array with multiple logical criteria:\n    # sst_between_-10_5 = sst[(sst > -10) & (sst < 5)]\n    \n    sns.distplot(sst_masked)\n    print ds.sst[0]\n    plt.imshow(ds.sst[0,::-100,::100])\n```\n\n    <xray.DataArray 'sst' (Y: 3298, X: 4500)>\n    array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n           ..., \n           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n           [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n           [ nan,  nan,  nan, ...,  nan,  nan,  nan]])\n    Coordinates:\n        MT         datetime64[ns] 2015-07-01T01:00:00.028800\n      * Y          (Y) int32 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n      * X          (X) int32 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n        Latitude   (Y, X) float32 -78.64 -78.64 -78.64 -78.64 -78.64 -78.64 ...\n        Longitude  (Y, X) float32 74.16 74.24 74.3199 74.4 74.48 74.5601 74.64 ...\n        Date       float64 2.015e+07\n    Attributes:\n        standard_name: sea_surface_temperature\n        units: degC\n        valid_range: [ -3.58215308  34.7584877 ]\n        long_name:  sea surf. temp.   [90.9H]\n\n\n\n![png](/content/images/2015/07/SST_data_11_2.png)\n\n\nWe can also very quickly render the raw data in a cartesian coordinate system using `imshow` from matplotlib. Note that we invert the second axis (latitude) since `imshow` defines its coordinate system from top-to-bottom.\n\n\n``` language-python\n    plt.imshow(ds.sst[0,::-1,...])\n```\n\n![png](/content/images/2015/07/SST_data_13_1.png)\n\n---\n\nA more sophisticated mapping system is provided by the `iris`/`cartopy` ecosystem. `iris` allows us to easily open structured climate data sets (of which this model output is an example), and automatically handles processing of metadata, such as timestamps and coordinate systems. It also has easy-to-use machinery for reprojecting, slicing through, or other basic manipulations of the data.\n\n\n``` language-python\n    import cartopy.crs as ccrs\n    \n    import iris\n    import iris.plot as iplt\n    import iris.quickplot as qplt\n```\n\nIt's easy enough to load a dataset using `iris`; just open the raw netCDF file, and we'll have a list of *Cube*s for each variable in it, each containing information on the structure of the coordinate system.\n\n\n``` language-python\n    cubes = iris.load(fn)\n    print cubes\n```\n\n    0: eastward_sea_water_velocity / (m/s) (time: 1; Layer: 1; latitude: 3298; longitude: 4500)\n    1: northward_sea_water_velocity / (m/s) (time: 1; Layer: 1; latitude: 3298; longitude: 4500)\n    2: sea_surface_salinity / (unknown)    (time: 1; latitude: 3298; longitude: 4500)\n    3: sea_surface_temperature / (degC)    (time: 1; latitude: 3298; longitude: 4500)\n    4: sea_water_potential_density / (unknown) (time: 1; Layer: 1; latitude: 3298; longitude: 4500)\n\n\nWe can extract a single variable (*Cube*) from the cube list using indexing notation, or the `extract` function. Printing the cube tells us all the metadata we need to know about it.\n\n\n``` language-python\n    #sst_c = cubes[3]\n    sst_c = cubes.extract(\"sea_surface_temperature\", strict=True)\n    print sst_c\n```\n\n    sea_surface_temperature / (degC)    (time: 1; latitude: 3298; longitude: 4500)\n         Dimension coordinates:\n              time                           x            -                -\n              latitude                       -            x                -\n                 point_spacing='even'\n              longitude                      -            -                x\n                 point_spacing='even'\n         Auxiliary coordinates:\n              date                           x            -                -\n              latitude                       -            x                x\n              longitude                      -            x                x\n                 modulo='360 degrees'\n         Attributes:\n              Conventions: CF-1.0\n              experiment: 90.9\n              history: archv2ncdf2d\n              institution: National Centers for Environmental Prediction\n              source: HYCOM archive file\n              title: HYCOM ATLb2.00\n\n\nGenerally speaking, the plotting machinery of `matplotlib` or `cartopy` can't handle 2D coordinate systems very well. So we'll try to re-project the data into a standard system. There are caveats here:\n\n1. The `project` function used below is not fancy; it applies a nearest-neighbor algorithm, so it does not conserve anything about the data. Ideally, you'd want to use something like a bilinear interpolation method to migrate data to the new coordinate system.\n\n2. This particular dataset is weird; the \"raw\" x-y coordinate system do not have names in the original netCDF file, but `iris` tags them as redundant latitude-longitude coordinates. It still retains the true 2D grid as Auxiliary coords, so we can just delete the mis-named coordinates without harming ourselves too much.\n\n3. The projection method is kind of slow, so we slice through a subset of the data as an example.\n\n4. We use a Plate Carree projection, but any one could do.\n\n\n``` language-python\n    import iris.analysis.cartography as iac\n    sst_d = sst_c[0, ::10, ::10]\n    \n    sst_d.remove_coord(sst_d.coord(var_name='Y'))\n    sst_d.remove_coord(sst_d.coord(var_name='X'))\n    \n    new_sst, extent = iac.project(sst_d, ccrs.PlateCarree())\n    \n    print new_sst\n```\n\n    sea_surface_temperature / (degC)    (projection_y_coordinate: 330; projection_x_coordinate: 450)\n         Dimension coordinates:\n              projection_y_coordinate                           x                             -\n              projection_x_coordinate                           -                             x\n         Auxiliary coordinates:\n              latitude                                          x                             x\n              longitude                                         x                             x\n         Scalar coordinates:\n              date: 20150701.0417\n              time: 2015-07-01 01:00:00\n         Attributes:\n              Conventions: CF-1.0\n              experiment: 90.9\n              history: archv2ncdf2d\n              institution: National Centers for Environmental Prediction\n              source: HYCOM archive file\n              title: HYCOM ATLb2.00\n\n\nWe can now easily plot the dataset using `iris`' interface to `matplotlib`, as a proof of concept:\n\n\n``` language-python\n    qplt.pcolormesh(new_sst)\n```\n\n![png](/content/images/2015/07/SST_data_23_1.png)\n\n--- \n\nAs a slightly fancier example, let's just plot SSTs in the vicinity of the Gulf Stream.\n\nFirst, we should extract a 'rectangular' box of SST data around the US Atlantic coast form the original dataset. `iris` has problems with 2D coordinate systems (most tools will!), so [Filipe Fernandes has built a package of workarounds that we could use to help](https://ocefpaf.github.io/python4oceanographers/blog/2015/06/29/tardis/). For simplicity, we'll just write a function for extracting the correct points from the 2D data (stolen form Filipe!)\n\n\n``` language-python\n    sst_d = sst_c[:]\n    \n    sst_d.remove_coord(sst_d.coord(var_name='Y'))\n    sst_d.remove_coord(sst_d.coord(var_name='X'))\n    \n    # add 360 to lon coord since it's not symmetric about the prime meridian\n    #bbox = [-78.+360., 34., -75.+360., 42.]\n    bbox = [-82.0+360., 32., -66.0+360., 45.]\n    \n    minmax = lambda x: (np.min(x), np.max(x))\n    \n    def bbox_extract_2Dcoords(cube, bbox):\n        \"\"\"\n        Extract a sub-set of a cube inside a lon, lat bounding box\n        bbox=[lon_min lon_max lat_min lat_max].\n        NOTE: This is a work around too subset an iris cube that has\n        2D lon, lat coords.\n        \n        \"\"\"\n        lons = cube.coord('longitude').points\n        lats = cube.coord('latitude').points\n        \n        lons_inregion = np.logical_and(lons > bbox[0], lons < bbox[2])\n        lats_inregion = np.logical_and(lats > bbox[1], lats < bbox[3])\n        inregion = np.logical_and(lons_inregion, lats_inregion)\n            \n        region_inds = np.where(inregion)\n        imin, imax = minmax(region_inds[0])\n        jmin, jmax = minmax(region_inds[1])\n        return cube[..., imin:imax+1, jmin:jmax+1]\n    \n    sst_sub = bbox_extract_2Dcoords(sst_d, bbox)\n    \n    print sst_sub\n```\n\n    sea_surface_temperature / (degC)    (time: 1; -- : 209; -- : 199)\n         Dimension coordinates:\n              time                           x       -         -\n         Auxiliary coordinates:\n              date                           x       -         -\n              latitude                       -       x         x\n              longitude                      -       x         x\n         Attributes:\n              Conventions: CF-1.0\n              experiment: 90.9\n              history: archv2ncdf2d\n              institution: National Centers for Environmental Prediction\n              source: HYCOM archive file\n              title: HYCOM ATLb2.00\n\n\nAs a reminder, we can collapse a dimension using a mathematical operation rather than just index it using numpy array slicing/indexing notation. Thus, we can quickly whip up a view of the sub-sliced SST data:\n\n\n``` language-python\n    sst_proc = sst_sub.collapsed('time', iris.analysis.MEAN)\n    #print sst_proc.shape\n    \n    plt.imshow(sst_proc.data[::-1])\n```\n\n![png](/content/images/2015/07/SST_data_27_2.png)\n\n\nWhat's especially nice now is that we have a much simpler X-Y/lat-lon coordinate system that doesn't deal with seams across the prime meridian or equator. So we don't even have to re-project our data! We can just plot it using the normal `matplotlib` routines. Below is an example of leveraging `cartopy`/`matplotlib` to build production-quality cartographic images.\n\n``` language-python\n    # Extra imports for annotating our map/plot\n    from cartopy.feature import NaturalEarthFeature, COLORS\n    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n    \n    # Control feature/boundary resolution\n    FEATURE_RES = '50m' # '10m' or '110m'\n    \n    # Extract the data and coordinate system, masking any invalid\n    # data points for convenience\n    sst_proc.data = np.ma.masked_invalid(sst_proc.data)\n    lon = sst_proc.coord('longitude').points\n    lat = sst_proc.coord('latitude').points\n    \n    # Set up the plotting canvas\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=ccrs.PlateCarree())\n    \n    # Set map extent\n    ax.set_extent([bbox[0], bbox[2], bbox[1], bbox[3]])\n    \n    # Add land political boundaries to map\n    land_data = NaturalEarthFeature('physical', 'land', FEATURE_RES,\n                                    edgecolor='face', # edgecolor == facecolor\n                                    facecolor=COLORS['land']) # a nice default\n    states = NaturalEarthFeature('cultural', \n                                 'admin_1_states_provinces', \n                                 FEATURE_RES,\n                                 edgecolor='grey', facecolor='none')\n    ax.add_feature(land_data)\n    ax.add_feature(states)\n    ax.coastlines(resolution=FEATURE_RES, lw=1.15)\n    \n    # Add some gridlines and use cartopy's convenience functions\n    # for formatting them\n    # Note - disabled for now, just change 'color' to enable\n    grid_style = dict(color='none', linestyle='-', lw=1.5)\n    gl = ax.gridlines(draw_labels=True, **grid_style)\n    gl.xlabels_top = gl.ylabels_right = False\n    gl.xformatter = LONGITUDE_FORMATTER\n    gl.yformatter = LATITUDE_FORMATTER\n    label_style = dict(size=11, color='black', weight='regular', \n                       family='serif')\n    gl.xlabel_style = gl.ylabel_style = label_style\n    \n    # Plot the actual data, using the projection system as a coordinate\n    # transform (I think this is right?)\n    pc = ax.pcolormesh(lon, lat, sst_proc.data, transform=ccrs.PlateCarree(),\n                       cmap=sst_palette)\n    cbar = fig.colorbar(pc, ax=ax, shrink=0.9) \n    cbar.ax.set_ylabel(sst_sub.units, labelpad=15., rotation=-90.,\n                       fontdict=dict(size=12, weight='bold'))\n    \n    ax.set_title(\"SST data from HYCOM/RTOFS\", loc='left',\n                 fontdict=dict(size=12, weight='bold'))\n\n```\n\n![png](/content/images/2015/07/SST_data_30_1.png)","html":"<p>Based on <a href=\"https://gist.github.com/darothen/84ae9a29154389fe45a5\">this notebook</a>, which highlights some basics on reading in RTOFS/netCDF output into Python, manipulating that data, and plotting it. For additional examples, <a href=\"https://ocefpaf.github.io/python4oceanographers/blog/2014/12/29/iris_ocean_models/\">Filipe Fernandes has a great example of similar operations on his blog</a>.</p>\n\n<pre><code class=\"language-python\">    import netCDF4 as nc\n    import numpy as np\n\n    %matplotlib inline\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    sns.set(style=\"ticks\")\n</code></pre>\n\n<p>Download some RTOFS global output. It's a rather large file, so be sure to comment out this command once it's already downloaded!</p>\n\n<pre><code class=\"language- language-bash\">#!curl -O ftp://ftpprd.ncep.noaa.gov/pub/data/nccf/com/rtofs/prod/rtofs.20150701/rtofs_glo_2ds_f001_1hrly_prog.nc\n</code></pre>\n\n<p>For starters, let's read in the data using the Unidate <code>netCDF4</code> module. This module gives very low-level access to the netCDF file - basically just its raw contents and metadata. We load the file directly into memory using the <code>Dataset</code> type, and print it to give an overview of its contents.</p>\n\n<pre><code class=\"language- language-python\">    fn = \"rtofs_glo_2ds_f001_1hrly_prog.nc\"\n    data = nc.Dataset(fn)\n    print data\n</code></pre>\n\n<pre><code>&lt;type 'netCDF4.Dataset'&gt;\nroot group (NETCDF3_CLASSIC data model, file format UNDEFINED):\n    Conventions: CF-1.0\n    title: HYCOM ATLb2.00\n    institution: National Centers for Environmental Prediction\n    source: HYCOM archive file\n    experiment: 90.9\n    history: archv2ncdf2d\n    dimensions(sizes): MT(1), Y(3298), X(4500), Layer(1)\n    variables(dimensions): float64 \u001b[4mMT\u001b[0m(MT), float64 \u001b[4mDate\u001b[0m(MT), int32 \u001b[4mLayer\u001b[0m(Layer), int32 \u001b[4mY\u001b[0m(Y), int32 \u001b[4mX\u001b[0m(X), float32 \u001b[4mLatitude\u001b[0m(Y,X), float32 \u001b[4mLongitude\u001b[0m(Y,X), float32 \u001b[4mu_velocity\u001b[0m(MT,Layer,Y,X), float32 \u001b[4mv_velocity\u001b[0m(MT,Layer,Y,X), float32 \u001b[4msst\u001b[0m(MT,Y,X), float32 \u001b[4msss\u001b[0m(MT,Y,X), float32 \u001b[4mlayer_density\u001b[0m(MT,Layer,Y,X)\n    groups: \n</code></pre>\n\n<p>Each <code>Dataset</code> object contains a dict-like interface for accessing variables, which can be selected by their <em>var_name</em> from the original netCDF file. Let's select the SST data and inspect it in more detail.</p>\n\n<pre><code class=\"language- language-python\">    sst = data.variables['sst']\n    print sst\n</code></pre>\n\n<pre><code>&lt;type 'netCDF4.Variable'&gt;\nfloat32 sst(MT, Y, X)\n    coordinates: Longitude Latitude Date\n    standard_name: sea_surface_temperature\n    units: degC\n    _FillValue: 1.26765e+30\n    valid_range: [ -3.58215308  34.7584877 ]\n    long_name:  sea surf. temp.   [90.9H]\nunlimited dimensions: MT\ncurrent shape = (1, 3298, 4500)\nfilling off\n</code></pre>\n\n<p>This gives us a quick overview of the sst data. It's a 3-dimensional dataset (time, latitude, and longitude). Furthermore, from the inspection of the full dataset, we can see that the latitude and longitude coordinates are actually aliases for a complex, 2D latitude-longitude system underpinning the model coordinate systems. </p>\n\n<hr />\n\n<p>Note that we can use standard netCDF terminal commands to also inspect the contents of the dataset:</p>\n\n<pre><code class=\"language- language-bash\">    !ncdump -h {fn}\n</code></pre>\n\n<pre><code>netcdf rtofs_glo_2ds_f001_1hrly_prog {\ndimensions:\n    MT = UNLIMITED ; // (1 currently)\n    Y = 3298 ;\n    X = 4500 ;\n    Layer = 1 ;\nvariables:\n    double MT(MT) ;\n        MT:long_name = \"time\" ;\n        MT:units = \"days since 1900-12-31 00:00:00\" ;\n        MT:calendar = \"standard\" ;\n        MT:axis = \"T\" ;\n    double Date(MT) ;\n        Date:long_name = \"date\" ;\n        Date:units = \"day as %Y%m%d.%f\" ;\n        Date:C_format = \"%13.4f\" ;\n        Date:FORTRAN_format = \"(f13.4)\" ;\n    int Layer(Layer) ;\n        Layer:units = \"layer\" ;\n        Layer:positive = \"down\" ;\n        Layer:axis = \"Z\" ;\n    int Y(Y) ;\n        Y:point_spacing = \"even\" ;\n        Y:axis = \"Y\" ;\n    int X(X) ;\n        X:point_spacing = \"even\" ;\n        X:axis = \"X\" ;\n    float Latitude(Y, X) ;\n        Latitude:standard_name = \"latitude\" ;\n        Latitude:units = \"degrees_north\" ;\n    float Longitude(Y, X) ;\n        Longitude:standard_name = \"longitude\" ;\n        Longitude:units = \"degrees_east\" ;\n        Longitude:modulo = \"360 degrees\" ;\n    float u_velocity(MT, Layer, Y, X) ;\n        u_velocity:coordinates = \"Longitude Latitude Date\" ;\n        u_velocity:standard_name = \"eastward_sea_water_velocity\" ;\n        u_velocity:units = \"m/s\" ;\n        u_velocity:_FillValue = 1.267651e+30f ;\n        u_velocity:valid_range = -2.127099f, 2.834078f ;\n        u_velocity:long_name = \" u-veloc. [90.9H]\" ;\n    float v_velocity(MT, Layer, Y, X) ;\n        v_velocity:coordinates = \"Longitude Latitude Date\" ;\n        v_velocity:standard_name = \"northward_sea_water_velocity\" ;\n        v_velocity:units = \"m/s\" ;\n        v_velocity:_FillValue = 1.267651e+30f ;\n        v_velocity:valid_range = -2.466692f, 2.390137f ;\n        v_velocity:long_name = \" v-veloc. [90.9H]\" ;\n    float sst(MT, Y, X) ;\n        sst:coordinates = \"Longitude Latitude Date\" ;\n        sst:standard_name = \"sea_surface_temperature\" ;\n        sst:units = \"degC\" ;\n        sst:_FillValue = 1.267651e+30f ;\n        sst:valid_range = -3.582153f, 34.75849f ;\n        sst:long_name = \" sea surf. temp.   [90.9H]\" ;\n    float sss(MT, Y, X) ;\n        sss:coordinates = \"Longitude Latitude Date\" ;\n        sss:standard_name = \"sea_surface_salinity\" ;\n        sss:units = \"psu\" ;\n        sss:_FillValue = 1.267651e+30f ;\n        sss:valid_range = 0.2699257f, 40.10468f ;\n        sss:long_name = \"sea surf. salnity  [90.9H]\" ;\n    float layer_density(MT, Layer, Y, X) ;\n        layer_density:coordinates = \"Longitude Latitude Date\" ;\n        layer_density:standard_name = \"sea_water_potential_density\" ;\n        layer_density:units = \"sigma\" ;\n        layer_density:_FillValue = 1.267651e+30f ;\n        layer_density:valid_range = 0.f, 0.f ;\n        layer_density:long_name = \" density [90.9H]\" ;\n\n// global attributes:\n        :Conventions = \"CF-1.0\" ;\n        :title = \"HYCOM ATLb2.00\" ;\n        :institution = \"National Centers for Environmental Prediction\" ;\n        :source = \"HYCOM archive file\" ;\n        :experiment = \"90.9\" ;\n        :history = \"archv2ncdf2d\" ;\n}\n</code></pre>\n\n<hr />\n\n<p>Another useful package for reading in netCDF or other structured datasets is <a href=\"http://xray.readthedocs.org/en/stable/\"><code>xray</code></a>. <code>xray</code> automatically labels coordinate axes and gives a <code>pandas</code>-like interface to manipulating data. For instance, here is an example of selecting the sst data from the netCDF file using <code>xray</code>, and plotting the distribution of temperature values:</p>\n\n<pre><code class=\"language- language-python\">    import xray\n    ds = xray.open_dataset(fn, decode_times=True)\n    sst = ds.sst.values.ravel()\n    sst_masked = sst[~np.isnan(sst)]\n\n    ## Masking a numpy array with multiple logical criteria:\n    # sst_between_-10_5 = sst[(sst &gt; -10) &amp; (sst &lt; 5)]\n\n    sns.distplot(sst_masked)\n    print ds.sst[0]\n    plt.imshow(ds.sst[0,::-100,::100])\n</code></pre>\n\n<pre><code>&lt;xray.DataArray 'sst' (Y: 3298, X: 4500)&gt;\narray([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       ..., \n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan]])\nCoordinates:\n    MT         datetime64[ns] 2015-07-01T01:00:00.028800\n  * Y          (Y) int32 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n  * X          (X) int32 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ...\n    Latitude   (Y, X) float32 -78.64 -78.64 -78.64 -78.64 -78.64 -78.64 ...\n    Longitude  (Y, X) float32 74.16 74.24 74.3199 74.4 74.48 74.5601 74.64 ...\n    Date       float64 2.015e+07\nAttributes:\n    standard_name: sea_surface_temperature\n    units: degC\n    valid_range: [ -3.58215308  34.7584877 ]\n    long_name:  sea surf. temp.   [90.9H]\n</code></pre>\n\n<p><img src=\"/content/images/2015/07/SST_data_11_2.png\" alt=\"png\" /></p>\n\n<p>We can also very quickly render the raw data in a cartesian coordinate system using <code>imshow</code> from matplotlib. Note that we invert the second axis (latitude) since <code>imshow</code> defines its coordinate system from top-to-bottom.</p>\n\n<pre><code class=\"language- language-python\">    plt.imshow(ds.sst[0,::-1,...])\n</code></pre>\n\n<p><img src=\"/content/images/2015/07/SST_data_13_1.png\" alt=\"png\" /></p>\n\n<hr />\n\n<p>A more sophisticated mapping system is provided by the <code>iris</code>/<code>cartopy</code> ecosystem. <code>iris</code> allows us to easily open structured climate data sets (of which this model output is an example), and automatically handles processing of metadata, such as timestamps and coordinate systems. It also has easy-to-use machinery for reprojecting, slicing through, or other basic manipulations of the data.</p>\n\n<pre><code class=\"language- language-python\">    import cartopy.crs as ccrs\n\n    import iris\n    import iris.plot as iplt\n    import iris.quickplot as qplt\n</code></pre>\n\n<p>It's easy enough to load a dataset using <code>iris</code>; just open the raw netCDF file, and we'll have a list of <em>Cube</em>s for each variable in it, each containing information on the structure of the coordinate system.</p>\n\n<pre><code class=\"language- language-python\">    cubes = iris.load(fn)\n    print cubes\n</code></pre>\n\n<pre><code>0: eastward_sea_water_velocity / (m/s) (time: 1; Layer: 1; latitude: 3298; longitude: 4500)\n1: northward_sea_water_velocity / (m/s) (time: 1; Layer: 1; latitude: 3298; longitude: 4500)\n2: sea_surface_salinity / (unknown)    (time: 1; latitude: 3298; longitude: 4500)\n3: sea_surface_temperature / (degC)    (time: 1; latitude: 3298; longitude: 4500)\n4: sea_water_potential_density / (unknown) (time: 1; Layer: 1; latitude: 3298; longitude: 4500)\n</code></pre>\n\n<p>We can extract a single variable (<em>Cube</em>) from the cube list using indexing notation, or the <code>extract</code> function. Printing the cube tells us all the metadata we need to know about it.</p>\n\n<pre><code class=\"language- language-python\">    #sst_c = cubes[3]\n    sst_c = cubes.extract(\"sea_surface_temperature\", strict=True)\n    print sst_c\n</code></pre>\n\n<pre><code>sea_surface_temperature / (degC)    (time: 1; latitude: 3298; longitude: 4500)\n     Dimension coordinates:\n          time                           x            -                -\n          latitude                       -            x                -\n             point_spacing='even'\n          longitude                      -            -                x\n             point_spacing='even'\n     Auxiliary coordinates:\n          date                           x            -                -\n          latitude                       -            x                x\n          longitude                      -            x                x\n             modulo='360 degrees'\n     Attributes:\n          Conventions: CF-1.0\n          experiment: 90.9\n          history: archv2ncdf2d\n          institution: National Centers for Environmental Prediction\n          source: HYCOM archive file\n          title: HYCOM ATLb2.00\n</code></pre>\n\n<p>Generally speaking, the plotting machinery of <code>matplotlib</code> or <code>cartopy</code> can't handle 2D coordinate systems very well. So we'll try to re-project the data into a standard system. There are caveats here:</p>\n\n<ol>\n<li><p>The <code>project</code> function used below is not fancy; it applies a nearest-neighbor algorithm, so it does not conserve anything about the data. Ideally, you'd want to use something like a bilinear interpolation method to migrate data to the new coordinate system.</p></li>\n<li><p>This particular dataset is weird; the \"raw\" x-y coordinate system do not have names in the original netCDF file, but <code>iris</code> tags them as redundant latitude-longitude coordinates. It still retains the true 2D grid as Auxiliary coords, so we can just delete the mis-named coordinates without harming ourselves too much.</p></li>\n<li><p>The projection method is kind of slow, so we slice through a subset of the data as an example.</p></li>\n<li><p>We use a Plate Carree projection, but any one could do.</p></li>\n</ol>\n\n<pre><code class=\"language- language-python\">    import iris.analysis.cartography as iac\n    sst_d = sst_c[0, ::10, ::10]\n\n    sst_d.remove_coord(sst_d.coord(var_name='Y'))\n    sst_d.remove_coord(sst_d.coord(var_name='X'))\n\n    new_sst, extent = iac.project(sst_d, ccrs.PlateCarree())\n\n    print new_sst\n</code></pre>\n\n<pre><code>sea_surface_temperature / (degC)    (projection_y_coordinate: 330; projection_x_coordinate: 450)\n     Dimension coordinates:\n          projection_y_coordinate                           x                             -\n          projection_x_coordinate                           -                             x\n     Auxiliary coordinates:\n          latitude                                          x                             x\n          longitude                                         x                             x\n     Scalar coordinates:\n          date: 20150701.0417\n          time: 2015-07-01 01:00:00\n     Attributes:\n          Conventions: CF-1.0\n          experiment: 90.9\n          history: archv2ncdf2d\n          institution: National Centers for Environmental Prediction\n          source: HYCOM archive file\n          title: HYCOM ATLb2.00\n</code></pre>\n\n<p>We can now easily plot the dataset using <code>iris</code>' interface to <code>matplotlib</code>, as a proof of concept:</p>\n\n<pre><code class=\"language- language-python\">    qplt.pcolormesh(new_sst)\n</code></pre>\n\n<p><img src=\"/content/images/2015/07/SST_data_23_1.png\" alt=\"png\" /></p>\n\n<hr />\n\n<p>As a slightly fancier example, let's just plot SSTs in the vicinity of the Gulf Stream.</p>\n\n<p>First, we should extract a 'rectangular' box of SST data around the US Atlantic coast form the original dataset. <code>iris</code> has problems with 2D coordinate systems (most tools will!), so <a href=\"https://ocefpaf.github.io/python4oceanographers/blog/2015/06/29/tardis/\">Filipe Fernandes has built a package of workarounds that we could use to help</a>. For simplicity, we'll just write a function for extracting the correct points from the 2D data (stolen form Filipe!)</p>\n\n<pre><code class=\"language- language-python\">    sst_d = sst_c[:]\n\n    sst_d.remove_coord(sst_d.coord(var_name='Y'))\n    sst_d.remove_coord(sst_d.coord(var_name='X'))\n\n    # add 360 to lon coord since it's not symmetric about the prime meridian\n    #bbox = [-78.+360., 34., -75.+360., 42.]\n    bbox = [-82.0+360., 32., -66.0+360., 45.]\n\n    minmax = lambda x: (np.min(x), np.max(x))\n\n    def bbox_extract_2Dcoords(cube, bbox):\n        \"\"\"\n        Extract a sub-set of a cube inside a lon, lat bounding box\n        bbox=[lon_min lon_max lat_min lat_max].\n        NOTE: This is a work around too subset an iris cube that has\n        2D lon, lat coords.\n\n        \"\"\"\n        lons = cube.coord('longitude').points\n        lats = cube.coord('latitude').points\n\n        lons_inregion = np.logical_and(lons &gt; bbox[0], lons &lt; bbox[2])\n        lats_inregion = np.logical_and(lats &gt; bbox[1], lats &lt; bbox[3])\n        inregion = np.logical_and(lons_inregion, lats_inregion)\n\n        region_inds = np.where(inregion)\n        imin, imax = minmax(region_inds[0])\n        jmin, jmax = minmax(region_inds[1])\n        return cube[..., imin:imax+1, jmin:jmax+1]\n\n    sst_sub = bbox_extract_2Dcoords(sst_d, bbox)\n\n    print sst_sub\n</code></pre>\n\n<pre><code>sea_surface_temperature / (degC)    (time: 1; -- : 209; -- : 199)\n     Dimension coordinates:\n          time                           x       -         -\n     Auxiliary coordinates:\n          date                           x       -         -\n          latitude                       -       x         x\n          longitude                      -       x         x\n     Attributes:\n          Conventions: CF-1.0\n          experiment: 90.9\n          history: archv2ncdf2d\n          institution: National Centers for Environmental Prediction\n          source: HYCOM archive file\n          title: HYCOM ATLb2.00\n</code></pre>\n\n<p>As a reminder, we can collapse a dimension using a mathematical operation rather than just index it using numpy array slicing/indexing notation. Thus, we can quickly whip up a view of the sub-sliced SST data:</p>\n\n<pre><code class=\"language- language-python\">    sst_proc = sst_sub.collapsed('time', iris.analysis.MEAN)\n    #print sst_proc.shape\n\n    plt.imshow(sst_proc.data[::-1])\n</code></pre>\n\n<p><img src=\"/content/images/2015/07/SST_data_27_2.png\" alt=\"png\" /></p>\n\n<p>What's especially nice now is that we have a much simpler X-Y/lat-lon coordinate system that doesn't deal with seams across the prime meridian or equator. So we don't even have to re-project our data! We can just plot it using the normal <code>matplotlib</code> routines. Below is an example of leveraging <code>cartopy</code>/<code>matplotlib</code> to build production-quality cartographic images.</p>\n\n<pre><code class=\"language- language-python\">    # Extra imports for annotating our map/plot\n    from cartopy.feature import NaturalEarthFeature, COLORS\n    from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n\n    # Control feature/boundary resolution\n    FEATURE_RES = '50m' # '10m' or '110m'\n\n    # Extract the data and coordinate system, masking any invalid\n    # data points for convenience\n    sst_proc.data = np.ma.masked_invalid(sst_proc.data)\n    lon = sst_proc.coord('longitude').points\n    lat = sst_proc.coord('latitude').points\n\n    # Set up the plotting canvas\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection=ccrs.PlateCarree())\n\n    # Set map extent\n    ax.set_extent([bbox[0], bbox[2], bbox[1], bbox[3]])\n\n    # Add land political boundaries to map\n    land_data = NaturalEarthFeature('physical', 'land', FEATURE_RES,\n                                    edgecolor='face', # edgecolor == facecolor\n                                    facecolor=COLORS['land']) # a nice default\n    states = NaturalEarthFeature('cultural', \n                                 'admin_1_states_provinces', \n                                 FEATURE_RES,\n                                 edgecolor='grey', facecolor='none')\n    ax.add_feature(land_data)\n    ax.add_feature(states)\n    ax.coastlines(resolution=FEATURE_RES, lw=1.15)\n\n    # Add some gridlines and use cartopy's convenience functions\n    # for formatting them\n    # Note - disabled for now, just change 'color' to enable\n    grid_style = dict(color='none', linestyle='-', lw=1.5)\n    gl = ax.gridlines(draw_labels=True, **grid_style)\n    gl.xlabels_top = gl.ylabels_right = False\n    gl.xformatter = LONGITUDE_FORMATTER\n    gl.yformatter = LATITUDE_FORMATTER\n    label_style = dict(size=11, color='black', weight='regular', \n                       family='serif')\n    gl.xlabel_style = gl.ylabel_style = label_style\n\n    # Plot the actual data, using the projection system as a coordinate\n    # transform (I think this is right?)\n    pc = ax.pcolormesh(lon, lat, sst_proc.data, transform=ccrs.PlateCarree(),\n                       cmap=sst_palette)\n    cbar = fig.colorbar(pc, ax=ax, shrink=0.9) \n    cbar.ax.set_ylabel(sst_sub.units, labelpad=15., rotation=-90.,\n                       fontdict=dict(size=12, weight='bold'))\n\n    ax.set_title(\"SST data from HYCOM/RTOFS\", loc='left',\n                 fontdict=dict(size=12, weight='bold'))\n</code></pre>\n\n<p><img src=\"/content/images/2015/07/SST_data_30_1.png\" alt=\"png\" /></p>","image":"/content/images/2015/07/SST_data_30_1-1.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1435854922707,"created_by":1,"updated_at":1435856477997,"updated_by":1,"published_at":1435856478000,"published_by":1},{"id":11,"uuid":"64948329-aca9-4c1d-81ab-c0195f2d1a7b","title":"Louisville Severe Wx, 7/13-14/2015","slug":"louisville-severe-wx-7132015","markdown":"<span style=\"color: red\">**LAST UPDATED:** 10:49 AM EDT (1459Z)</span>\n\n## Stormy Afternoon\n\nToday's forecast is a bit of step down from yesterday. There's still a wind/rain threat later this afternoon, but there's a bit less energy for storms to tap into.\n\nStorms should develop in Western KY and areas further West in response to daytime heating; those storms will likely develop into a system with torrential rains and the potential for strong straight-line winds. Any isolated thunderstorms also pose a threat for large hail, which is one of the SPC's primary concerns for today:\n\n![SPC Hail CO 13Z 7/14/2015](http://www.spc.noaa.gov/products/outlook/day1probotlk_1300_hail.gif?1436885252308)\n\nHonestly, I think it's a rather hit-or-miss situation. Any areas that *do* feel a storm will certainly not like it; the grounds are totally soaked through much of north-central Kentucky, so I don't think anyone will appreciate the immediate flooding any rains will bring. But I don't see a major organized severe weather threat or even one that rivals the potential from yesterday. We'll see how that changes with the next set of model runs before the storm.\n\nExpect storms sometime after 3PM, but before dark.\n\n**Update 9 - 8:16 PM EDT (0016Z+1)**\n\n## Overnight Severe Weather\n\nRound 2 should be impinging on the Louisville area around midnight this evening, although timing could vary by +/- an hour.\n\nOver the next few hours, there's a chance for scattered thunderstorms. A few of these could be severe, especially any that leapfrog ahead of the next developing mesoscale convective system. Such a system is already beginning to brew in the form of discrete, severe thunderstorm cells south of Chicago -\n\n![evening chicago radar](/content/images/2015/07/Picture-3.png)\n\nOver the next few hours, some of these storms will congeal into another squall line, which will propagate towards Louisville. The [Storm Prediction Center anticipates extending a <span style=\"color: purple\">Tornado Watch</span>](http://www.spc.noaa.gov/products/md/md1399.html) to cover much of south-central Indiana through the overnight hours; all severe weather threats are still in play, but any discrete cell that pops up before the main MCS could rotate and drop large hail or a quick tornado. Thus, there is still a small albeit not zero tornado threat for Louisville if any one of these cells persists.\n\n**Hazard Overview**\n\nThere exists the potential for more damaging straight-line winds capable of knocking over trees and power lines. This is *particularly* true for those areas which were really thoroughly soaked through by the afternoon event. Hail and an isolated tornado isn't out of the question. However, the persistent danger will be <span style=\"color: navy\">**Flash Flooding**</span>, which is all the more dangerous when driving after sun down.\n\nI'll probably offer one or two more updates before I leave MIT to catch the last subway this evening.\n\n**UPDATE 8 - 3:25 PM EDT (0025Z)**\n\nA second round could be beginning for the Western half of Jefferson County as the squall line has back-built somewhat in the presence of a confluence of several boundaries. **Flash Flood Warnings** are still in effect for the county. \n\n**UPDATE 7 - 2:57 PM EDT (1857Z)**\n\nNWS has extended the <span style=\"color: red\">**SEVERE THUNDERSTORM WARNING**</span> through 3:30 PM EDT. Strongest winds are around Hurstborne and eastern parts of Jefferson County. Should be finished swinging through the area in another 45 minutes.\n\nI'll update with some damage reports later, and then the forecast for this evening's events around 8PM after my softball match.\n\n**UPDATE 6 - 2:41 PM EDT (1841Z)**\n\nStrong winds moving into Downtown Louisville, Highlands, etc. Still potential for localized wind gusts in the ~70mph range, but haven't seen too many ground-truth reports just yet.\n\nPicture from the dad, looking due North across I-64 from Bluegrass Parkway in industrial park north of Jeffersontown:\n\n![incoming squall line](/content/images/2015/07/IMG_20150713_143650.jpg)\n\n**UPDATE 5 - 2:22 PM EDT (1822Z)**\n\n[WAVE3-TV](http://www.wave3.com/category/200260/wave-3-live) reporting wind gusts of ~55mph in Oldham County; power outages in Prospect.\n\n**UPDATE 4 - 2:17 PM EDT (1817Z)**\n\nA <span style=\"color: red\">**SEVERE THUNDERSTORM WARNING**</span> is in effect for Jefferson County (KY) until 3:00 PM EDT.\n\nhttp://forecast.weather.gov/showsigwx.php?warnzone=KYZ030&warncounty=KYC111&firewxzone=KYZ030&local_place1=Lynnview%20KY&product1=Severe+Thunderstorm+Warning&lat=38.1788&lon=-85.7103#.VaQAWMZVhBc\n\n**UPDATE 3 - 2:03 PM EDT (1803Z)**\n\nLost of [storm reports already coming in from central Indiana](http://www.spc.noaa.gov/climo/reports/today.html); **Flash Flood Warning** in effect for Louisville, east of I-65 as storms move towards the Ohio River:\n\n![radar update 203](/content/images/2015/07/Picture-2.png)\n\nWorst of storms should be east of I-65.\n\n**UPDATE 2 - 1:43 PM EDT (1743Z)**\n\nSee [Forecast Discussion]() below.\n\n**UPDATE 1 - 1:04 PM EDT (1704Z)**\n\n[A Severe Thunderstorm Watch has been issued for all of Central/Eastern Kentucky through 8 PM this evening](http://www.spc.noaa.gov/products/watch/ww0410_radar_big.gif):\n\n![severe thunderstorm watch 410](http://www.spc.noaa.gov/products/watch/ww0410_radar_big.gif)\n\n\n\n**Initial Post**\n\n## Overview\n\nTwo-three waves of severe weather will impact the Louisville area this afternoon and late in the evening. The first wave is currently impacting Indianapolis, and should arrive in Louisville around 2-3 PM (18-19Z). The second wave would occur much later, after dark - probably not before 11 PM or midnight, and has the potential to be more significant than this afternoon's event. From each wave, the primary threats are straight-line damaging winds (expect localized winds of 70-80 mph) and flash flooding (a 100% given, considering this weekend's weather). There is a small threat for isolated, short-lived tornadoes, either within the squall in itself as it goes through local fluctuations in strength, but especially moreso from any discrete cells that fire up ahead of the complexes and can tap into the strong instability over much of southern Indiana and central Kentucky. A third event (albeit weaker) is expected tomorrow in the early afternoon.\n\nFor those of you who keep score, the SPC *just* [re-issued a Moderate categorical outlook for N Central Kentucky](http://www.spc.noaa.gov/products/outlook/day1otlk_1630.gif?1436805394458).\n\n## Afternoon squall line / derecho\n\nCurrently, a squall line associated with a much larger-scale circulation (a mesoscale convective vortex) around Lake Michigan is advancing southward through central Indiana. At 16Z it shows up pretty dramatically on visible satellite imagery:\n\n![GOES visible 16Z](/content/images/2015/07/BC3C7235-393A-428F-BE43-F3D7D410FEFE.png)\n\nAs the squall line advances and threatens the Louisville area, the SPC will [shortly issue a Severe Thunderstorm Watch](http://www.spc.noaa.gov/products/md/md1390.html), with the main weather impacts around 2-3 PM EDT (18-19Z). A squall line like this will bring significant rain and winds; where uncertainty lies is in the precise character of the squall line. The [Louisville NWS office offers two scenarios, which I've condensed below:]\n\n> Scenario #1\n>\n> The main player for today`s evolution will be current complex... we [could be] looking at a full blown Derecho event as we would have all day to destabilize and it would arrive near peak heating... Widespread damaging winds would be a certainty along  with Flash Flooding... [i]solated instances of straight-line winds over 80 mph would be possible along with isolated tornadoes.\n>\n> Scenario #2\n>\n> The second scenario involves a few complexes/bowing structures developing ahead of the main [squall line]... [i]f this occurs, onset of severe weather/flooding will occur by midday to mid afternoon.. [w]e will still be primed for large bowing segments that will yield damaging winds and flash flooding. Given several rounds of convection, Flash Flooding would be the bigger concern along with the rounds of damaging winds. Isolated tornadoes would be possible. \n\nAs of 12:42 PM EDT, severe watches are already in effect for northern parts of the Louisville news broadcast area as the squall line edges towards Bloomington:\n\n![squall line 12:46 PM EDT](/content/images/2015/07/Picture-1.png)\n\n## Forecast Discussion\n\nThis is really a classic midwestern Summer severe weather event, albeit one that could sustain a [derecho](http://www.weather.gov/lmk/derecho) - a special type of long-lived storm which brings sustained, damaging straight line winds. A similar event struck the Louisville area 11 years ago to the day, [bringing widespread reports of wind damage](http://www.weather.gov/lmk/13july2004_derecho).\n\nThere are two key ingredients to today's storm:\n\n**1) Widespread instability**\n\n[It's currently 92F with a dewpoint of 75F at SDF](http://aviationweather.gov/adds/metars?station_ids=KSDF&std_trans=translated&chk_metars=on&hoursStr=past+3+hours&submitmet=Submit), which is actually a tad lower than some other pockets in the Kentucky. That's the type of environment where you step outside and can simply feel the energy loaded in the atmosphere. Storms are a given on days like today. So what makes today particularly bad for severe weather?\n\n**2) \"Ring of Fire\"**\n\nToday's 250mb setup (reproduced from a high resolution model run below) tells the story:\n\n![250mb ring of fire](http://rapidrefresh.noaa.gov/RAP/for_web/rap_jet/2015071314/conus/wind_250_f03.png)\n\nThe brightly-colored blob in the northern plains is a jet streak - an area of stronger-than-their-surroundings winds within the jet stream. Under conditions like this, the \"bubble\" underneath the right generally experiences stagnant, warm conditions. Moisture and momentum tend to accumulate in the exit region of the streak - over the Great Lakes, where the current squall line originated and where a mesoscale convective vortex is setting up. The accumulation of moisture, combined with the \"shear\" in the environment - the way winds change speed and direction as you go higher in altitude - is a potent combination to whip up strong thunderstorms. Those that grow into large, organized complexes can tap the strong winds aloft and mix them towards the surface, producing dangerous straight line wind damage.\n\nMost importantly, in strongly-sheared environments like this, severe weather tends to \"organize.\" Thunderstorms have life-cycles; as they mature, they produce rain in the regions where they derive their strength, effectively killing them. However, in strongly-sheared environments (like today), the rain that mature thunderstorms produce falls in different regions. The cooling producing by this rain produces boundaries which propagate, interact with the original storm, and ultimately produce a neighboring, nascent storm cell. That's actually happening right now in Southern Indiana as storms \"back-build.\"","html":"<p><span style=\"color: red\"><strong>LAST UPDATED:</strong> 10:49 AM EDT (1459Z)</span></p>\n\n<h2 id=\"stormyafternoon\">Stormy Afternoon</h2>\n\n<p>Today's forecast is a bit of step down from yesterday. There's still a wind/rain threat later this afternoon, but there's a bit less energy for storms to tap into.</p>\n\n<p>Storms should develop in Western KY and areas further West in response to daytime heating; those storms will likely develop into a system with torrential rains and the potential for strong straight-line winds. Any isolated thunderstorms also pose a threat for large hail, which is one of the SPC's primary concerns for today:</p>\n\n<p><img src=\"http://www.spc.noaa.gov/products/outlook/day1probotlk_1300_hail.gif?1436885252308\" alt=\"SPC Hail CO 13Z 7/14/2015\" /></p>\n\n<p>Honestly, I think it's a rather hit-or-miss situation. Any areas that <em>do</em> feel a storm will certainly not like it; the grounds are totally soaked through much of north-central Kentucky, so I don't think anyone will appreciate the immediate flooding any rains will bring. But I don't see a major organized severe weather threat or even one that rivals the potential from yesterday. We'll see how that changes with the next set of model runs before the storm.</p>\n\n<p>Expect storms sometime after 3PM, but before dark.</p>\n\n<p><strong>Update 9 - 8:16 PM EDT (0016Z+1)</strong></p>\n\n<h2 id=\"overnightsevereweather\">Overnight Severe Weather</h2>\n\n<p>Round 2 should be impinging on the Louisville area around midnight this evening, although timing could vary by +/- an hour.</p>\n\n<p>Over the next few hours, there's a chance for scattered thunderstorms. A few of these could be severe, especially any that leapfrog ahead of the next developing mesoscale convective system. Such a system is already beginning to brew in the form of discrete, severe thunderstorm cells south of Chicago -</p>\n\n<p><img src=\"/content/images/2015/07/Picture-3.png\" alt=\"evening chicago radar\" /></p>\n\n<p>Over the next few hours, some of these storms will congeal into another squall line, which will propagate towards Louisville. The <a href=\"http://www.spc.noaa.gov/products/md/md1399.html\">Storm Prediction Center anticipates extending a <span style=\"color: purple\">Tornado Watch</span></a> to cover much of south-central Indiana through the overnight hours; all severe weather threats are still in play, but any discrete cell that pops up before the main MCS could rotate and drop large hail or a quick tornado. Thus, there is still a small albeit not zero tornado threat for Louisville if any one of these cells persists.</p>\n\n<p><strong>Hazard Overview</strong></p>\n\n<p>There exists the potential for more damaging straight-line winds capable of knocking over trees and power lines. This is <em>particularly</em> true for those areas which were really thoroughly soaked through by the afternoon event. Hail and an isolated tornado isn't out of the question. However, the persistent danger will be <span style=\"color: navy\"><strong>Flash Flooding</strong></span>, which is all the more dangerous when driving after sun down.</p>\n\n<p>I'll probably offer one or two more updates before I leave MIT to catch the last subway this evening.</p>\n\n<p><strong>UPDATE 8 - 3:25 PM EDT (0025Z)</strong></p>\n\n<p>A second round could be beginning for the Western half of Jefferson County as the squall line has back-built somewhat in the presence of a confluence of several boundaries. <strong>Flash Flood Warnings</strong> are still in effect for the county. </p>\n\n<p><strong>UPDATE 7 - 2:57 PM EDT (1857Z)</strong></p>\n\n<p>NWS has extended the <span style=\"color: red\"><strong>SEVERE THUNDERSTORM WARNING</strong></span> through 3:30 PM EDT. Strongest winds are around Hurstborne and eastern parts of Jefferson County. Should be finished swinging through the area in another 45 minutes.</p>\n\n<p>I'll update with some damage reports later, and then the forecast for this evening's events around 8PM after my softball match.</p>\n\n<p><strong>UPDATE 6 - 2:41 PM EDT (1841Z)</strong></p>\n\n<p>Strong winds moving into Downtown Louisville, Highlands, etc. Still potential for localized wind gusts in the ~70mph range, but haven't seen too many ground-truth reports just yet.</p>\n\n<p>Picture from the dad, looking due North across I-64 from Bluegrass Parkway in industrial park north of Jeffersontown:</p>\n\n<p><img src=\"/content/images/2015/07/IMG_20150713_143650.jpg\" alt=\"incoming squall line\" /></p>\n\n<p><strong>UPDATE 5 - 2:22 PM EDT (1822Z)</strong></p>\n\n<p><a href=\"http://www.wave3.com/category/200260/wave-3-live\">WAVE3-TV</a> reporting wind gusts of ~55mph in Oldham County; power outages in Prospect.</p>\n\n<p><strong>UPDATE 4 - 2:17 PM EDT (1817Z)</strong></p>\n\n<p>A <span style=\"color: red\"><strong>SEVERE THUNDERSTORM WARNING</strong></span> is in effect for Jefferson County (KY) until 3:00 PM EDT.</p>\n\n<p><a href=\"http://forecast.weather.gov/showsigwx.php?warnzone=KYZ030&amp;warncounty=KYC111&amp;firewxzone=KYZ030&amp;local_place1=Lynnview%20KY&amp;product1=Severe+Thunderstorm+Warning&amp;lat=38.1788&amp;lon=-85.7103#.VaQAWMZVhBc\">http://forecast.weather.gov/showsigwx.php?warnzone=KYZ030&amp;warncounty=KYC111&amp;firewxzone=KYZ030&amp;local_place1=Lynnview%20KY&amp;product1=Severe+Thunderstorm+Warning&amp;lat=38.1788&amp;lon=-85.7103#.VaQAWMZVhBc</a></p>\n\n<p><strong>UPDATE 3 - 2:03 PM EDT (1803Z)</strong></p>\n\n<p>Lost of <a href=\"http://www.spc.noaa.gov/climo/reports/today.html\">storm reports already coming in from central Indiana</a>; <strong>Flash Flood Warning</strong> in effect for Louisville, east of I-65 as storms move towards the Ohio River:</p>\n\n<p><img src=\"/content/images/2015/07/Picture-2.png\" alt=\"radar update 203\" /></p>\n\n<p>Worst of storms should be east of I-65.</p>\n\n<p><strong>UPDATE 2 - 1:43 PM EDT (1743Z)</strong></p>\n\n<p>See <a href=\"\">Forecast Discussion</a> below.</p>\n\n<p><strong>UPDATE 1 - 1:04 PM EDT (1704Z)</strong></p>\n\n<p><a href=\"http://www.spc.noaa.gov/products/watch/ww0410_radar_big.gif\">A Severe Thunderstorm Watch has been issued for all of Central/Eastern Kentucky through 8 PM this evening</a>:</p>\n\n<p><img src=\"http://www.spc.noaa.gov/products/watch/ww0410_radar_big.gif\" alt=\"severe thunderstorm watch 410\" /></p>\n\n<p><strong>Initial Post</strong></p>\n\n<h2 id=\"overview\">Overview</h2>\n\n<p>Two-three waves of severe weather will impact the Louisville area this afternoon and late in the evening. The first wave is currently impacting Indianapolis, and should arrive in Louisville around 2-3 PM (18-19Z). The second wave would occur much later, after dark - probably not before 11 PM or midnight, and has the potential to be more significant than this afternoon's event. From each wave, the primary threats are straight-line damaging winds (expect localized winds of 70-80 mph) and flash flooding (a 100% given, considering this weekend's weather). There is a small threat for isolated, short-lived tornadoes, either within the squall in itself as it goes through local fluctuations in strength, but especially moreso from any discrete cells that fire up ahead of the complexes and can tap into the strong instability over much of southern Indiana and central Kentucky. A third event (albeit weaker) is expected tomorrow in the early afternoon.</p>\n\n<p>For those of you who keep score, the SPC <em>just</em> <a href=\"http://www.spc.noaa.gov/products/outlook/day1otlk_1630.gif?1436805394458\">re-issued a Moderate categorical outlook for N Central Kentucky</a>.</p>\n\n<h2 id=\"afternoonsqualllinederecho\">Afternoon squall line / derecho</h2>\n\n<p>Currently, a squall line associated with a much larger-scale circulation (a mesoscale convective vortex) around Lake Michigan is advancing southward through central Indiana. At 16Z it shows up pretty dramatically on visible satellite imagery:</p>\n\n<p><img src=\"/content/images/2015/07/BC3C7235-393A-428F-BE43-F3D7D410FEFE.png\" alt=\"GOES visible 16Z\" /></p>\n\n<p>As the squall line advances and threatens the Louisville area, the SPC will <a href=\"http://www.spc.noaa.gov/products/md/md1390.html\">shortly issue a Severe Thunderstorm Watch</a>, with the main weather impacts around 2-3 PM EDT (18-19Z). A squall line like this will bring significant rain and winds; where uncertainty lies is in the precise character of the squall line. The [Louisville NWS office offers two scenarios, which I've condensed below:]</p>\n\n<blockquote>\n  <p>Scenario #1</p>\n  \n  <p>The main player for today`s evolution will be current complex... we [could be] looking at a full blown Derecho event as we would have all day to destabilize and it would arrive near peak heating... Widespread damaging winds would be a certainty along  with Flash Flooding... [i]solated instances of straight-line winds over 80 mph would be possible along with isolated tornadoes.</p>\n  \n  <p>Scenario #2</p>\n  \n  <p>The second scenario involves a few complexes/bowing structures developing ahead of the main [squall line]... [i]f this occurs, onset of severe weather/flooding will occur by midday to mid afternoon.. [w]e will still be primed for large bowing segments that will yield damaging winds and flash flooding. Given several rounds of convection, Flash Flooding would be the bigger concern along with the rounds of damaging winds. Isolated tornadoes would be possible. </p>\n</blockquote>\n\n<p>As of 12:42 PM EDT, severe watches are already in effect for northern parts of the Louisville news broadcast area as the squall line edges towards Bloomington:</p>\n\n<p><img src=\"/content/images/2015/07/Picture-1.png\" alt=\"squall line 12:46 PM EDT\" /></p>\n\n<h2 id=\"forecastdiscussion\">Forecast Discussion</h2>\n\n<p>This is really a classic midwestern Summer severe weather event, albeit one that could sustain a <a href=\"http://www.weather.gov/lmk/derecho\">derecho</a> - a special type of long-lived storm which brings sustained, damaging straight line winds. A similar event struck the Louisville area 11 years ago to the day, <a href=\"http://www.weather.gov/lmk/13july2004_derecho\">bringing widespread reports of wind damage</a>.</p>\n\n<p>There are two key ingredients to today's storm:</p>\n\n<p><strong>1) Widespread instability</strong></p>\n\n<p><a href=\"http://aviationweather.gov/adds/metars?station_ids=KSDF&amp;std_trans=translated&amp;chk_metars=on&amp;hoursStr=past+3+hours&amp;submitmet=Submit\">It's currently 92F with a dewpoint of 75F at SDF</a>, which is actually a tad lower than some other pockets in the Kentucky. That's the type of environment where you step outside and can simply feel the energy loaded in the atmosphere. Storms are a given on days like today. So what makes today particularly bad for severe weather?</p>\n\n<p><strong>2) \"Ring of Fire\"</strong></p>\n\n<p>Today's 250mb setup (reproduced from a high resolution model run below) tells the story:</p>\n\n<p><img src=\"http://rapidrefresh.noaa.gov/RAP/for_web/rap_jet/2015071314/conus/wind_250_f03.png\" alt=\"250mb ring of fire\" /></p>\n\n<p>The brightly-colored blob in the northern plains is a jet streak - an area of stronger-than-their-surroundings winds within the jet stream. Under conditions like this, the \"bubble\" underneath the right generally experiences stagnant, warm conditions. Moisture and momentum tend to accumulate in the exit region of the streak - over the Great Lakes, where the current squall line originated and where a mesoscale convective vortex is setting up. The accumulation of moisture, combined with the \"shear\" in the environment - the way winds change speed and direction as you go higher in altitude - is a potent combination to whip up strong thunderstorms. Those that grow into large, organized complexes can tap the strong winds aloft and mix them towards the surface, producing dangerous straight line wind damage.</p>\n\n<p>Most importantly, in strongly-sheared environments like this, severe weather tends to \"organize.\" Thunderstorms have life-cycles; as they mature, they produce rain in the regions where they derive their strength, effectively killing them. However, in strongly-sheared environments (like today), the rain that mature thunderstorms produce falls in different regions. The cooling producing by this rain produces boundaries which propagate, interact with the original storm, and ultimately produce a neighboring, nascent storm cell. That's actually happening right now in Southern Indiana as storms \"back-build.\"</p>","image":"/content/images/2015/07/1F48BDD5-D60B-40ED-AD8F-C1FFA4F064B7.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":"","meta_description":"Liveblog of severe weather event in Louisville, Kentucky - July 13, 2015","author_id":1,"created_at":1436803462349,"created_by":1,"updated_at":1436908727435,"updated_by":1,"published_at":1436805785532,"published_by":1},{"id":12,"uuid":"82c550db-df2c-4c4c-a186-8136b31fbfe2","title":"Abandoning Iris","slug":"abandoning-iris","markdown":"Seven years ago, when I first started working with climate model output and analysis within Python, the software stack we had available was pretty shoddy. Although [direct interfaces to netCDF](https://github.com/Unidata/netcdf4-python) (the *de facto* standard data format in climate science) existed, they could be kind of clunky. They didn't have smart ways to manipulate coordinate systems attached to the data, they didn't play nice with updating metadata, and they usually had dependencies which were difficult to deal with (considering the bifurcation between netCDF3/netCDF4/HDF5). \n\nSome okay toolkits existed, though. A [package maintained by NCAR](https://www.pyngl.ucar.edu/Nio.shtml) exposed a good interface for manipulating netCDF data, and allowed you to play directly with NCL - a graphics scripting language used in the atmospheric sciences). But working with these tools - and cartographic supplements like [Basemap](http://matplotlib.org/basemap/) was very hacky and headache-inducing.\n\n### Enter Cartopy/Iris\n\nWhen I started my PhD, I knew it was time for a change. I wanted to build better, flexible packages for repeating my various analyses with minimal repetition of code and with the hopes that other people could use my code whenever they wanted. The stack wasn't up to the task.\n\nLuckily, two major toolkits came to maturity around this time: [cartopy](http://scitools.org.uk/cartopy/docs/latest/index.html) and [iris](http://scitools.org.uk/iris/docs/latest/index.html). Cartopy is a Basemap-replacement, with some more sophisticated routines and a simpler interface for dealing with re-gridding, map projections, and combining geographical data from all sorts of different sources. For instance, one of the gallery examples from cartopy is a visualization of Hurricane Katrina's track and impacts in the US:\n\n![Katrina cartopy example](http://scitools.org.uk/cartopy/docs/latest/_images/hurricane_katrina_01_00.png)\n\nThe script which generates this figure is incredibly simple; suddenly, you could build GIS-type graphics with minimal effort! Within cartopy, you can also easily combine geographical data from many different sources. This quick plot I made for a thesis committee meeting combines two completely different MODIS satellite data sources and output from the online HYSPLIT calculator:\n\n![fire map april 2011](/content/images/2015/07/MODIS_CentAm_Fires_AOD_Hysplit_4_24.png)\n\nAs another example, here's a visualization combining some GOES-R IR satellite imagery with timeseries data from a flight during the [MACPEX field campaign](http://www-air.larc.nasa.gov/missions/macpex/macpex.html):\n\n![MACPEX GOES-R IR](/content/images/2015/07/IR-4_flightpath_20110425_183229.png)\n\nIris is a toolkit which integrates directly with cartopy by wrapping geophysical data sets. Rather than load a dataset directly using a low-level interface, iris exposes a different API which allows you to manipulated data more semantically. You can slice through dimensions, perform aggregations or apply functions over them, and generally pipeline your analyses in such a way that you preserve the metadata attached to your dataset. It can also handle multi-file datasets by seamlessly concatenating over record dimensions. But best of all, it wraps the matplotlib+cartopy visualization ecosystem so that you can very quickly and easily generate maps of your data.\n\n### Python 3\n\nI was content with these tools until I decided to suck it up and migrate to Python 3. That posed a problem - cartopy works *ok* with Python 3 (as in, I haven't run into any issues yet). But iris emphatically doesn't. It's also not clear when iris will become Python 3-compliant. \n\nLuckily, there are *fantastic* alternatives to iris available. One of my favorites is [xray](http://xray.readthedocs.org/en/stable/), which exposes an API offering much of the same sort semantic handling of your netCDF data, but in a less-clunky, simpler manner. It also directly extends a good deal of the logic behind pandas, which itself is a fantastic way to manipulate timeseries/indexed datasets. Xray also works with Python 3 out of the box, and can very easily work with cartopy plotting routines ([it even has a plotting library in the works](http://xray.readthedocs.org/en/feature-plotting/)).\n\n### Conclusions\n\nI still like iris. Up until this week, I was developing my analysis toolkit such that you could work with either xray/iris in any context, and seamlessly convert between the two. But the lack of Python 3 support - at the critical time *when I actually have some extra time to get used to the changes* - is enough to demote it from the top of my scientific Python stack. This doesn't even get to all the awesome goodies that xray implements, like [dask integration for out-of-core computing](http://dask.pydata.org/en/latest/).\n\nSo for now, there's a new workhorse in my toolkit!","html":"<p>Seven years ago, when I first started working with climate model output and analysis within Python, the software stack we had available was pretty shoddy. Although <a href=\"https://github.com/Unidata/netcdf4-python\">direct interfaces to netCDF</a> (the <em>de facto</em> standard data format in climate science) existed, they could be kind of clunky. They didn't have smart ways to manipulate coordinate systems attached to the data, they didn't play nice with updating metadata, and they usually had dependencies which were difficult to deal with (considering the bifurcation between netCDF3/netCDF4/HDF5). </p>\n\n<p>Some okay toolkits existed, though. A <a href=\"https://www.pyngl.ucar.edu/Nio.shtml\">package maintained by NCAR</a> exposed a good interface for manipulating netCDF data, and allowed you to play directly with NCL - a graphics scripting language used in the atmospheric sciences). But working with these tools - and cartographic supplements like <a href=\"http://matplotlib.org/basemap/\">Basemap</a> was very hacky and headache-inducing.</p>\n\n<h3 id=\"entercartopyiris\">Enter Cartopy/Iris</h3>\n\n<p>When I started my PhD, I knew it was time for a change. I wanted to build better, flexible packages for repeating my various analyses with minimal repetition of code and with the hopes that other people could use my code whenever they wanted. The stack wasn't up to the task.</p>\n\n<p>Luckily, two major toolkits came to maturity around this time: <a href=\"http://scitools.org.uk/cartopy/docs/latest/index.html\">cartopy</a> and <a href=\"http://scitools.org.uk/iris/docs/latest/index.html\">iris</a>. Cartopy is a Basemap-replacement, with some more sophisticated routines and a simpler interface for dealing with re-gridding, map projections, and combining geographical data from all sorts of different sources. For instance, one of the gallery examples from cartopy is a visualization of Hurricane Katrina's track and impacts in the US:</p>\n\n<p><img src=\"http://scitools.org.uk/cartopy/docs/latest/_images/hurricane_katrina_01_00.png\" alt=\"Katrina cartopy example\" /></p>\n\n<p>The script which generates this figure is incredibly simple; suddenly, you could build GIS-type graphics with minimal effort! Within cartopy, you can also easily combine geographical data from many different sources. This quick plot I made for a thesis committee meeting combines two completely different MODIS satellite data sources and output from the online HYSPLIT calculator:</p>\n\n<p><img src=\"/content/images/2015/07/MODIS_CentAm_Fires_AOD_Hysplit_4_24.png\" alt=\"fire map april 2011\" /></p>\n\n<p>As another example, here's a visualization combining some GOES-R IR satellite imagery with timeseries data from a flight during the <a href=\"http://www-air.larc.nasa.gov/missions/macpex/macpex.html\">MACPEX field campaign</a>:</p>\n\n<p><img src=\"/content/images/2015/07/IR-4_flightpath_20110425_183229.png\" alt=\"MACPEX GOES-R IR\" /></p>\n\n<p>Iris is a toolkit which integrates directly with cartopy by wrapping geophysical data sets. Rather than load a dataset directly using a low-level interface, iris exposes a different API which allows you to manipulated data more semantically. You can slice through dimensions, perform aggregations or apply functions over them, and generally pipeline your analyses in such a way that you preserve the metadata attached to your dataset. It can also handle multi-file datasets by seamlessly concatenating over record dimensions. But best of all, it wraps the matplotlib+cartopy visualization ecosystem so that you can very quickly and easily generate maps of your data.</p>\n\n<h3 id=\"python3\">Python 3</h3>\n\n<p>I was content with these tools until I decided to suck it up and migrate to Python 3. That posed a problem - cartopy works <em>ok</em> with Python 3 (as in, I haven't run into any issues yet). But iris emphatically doesn't. It's also not clear when iris will become Python 3-compliant. </p>\n\n<p>Luckily, there are <em>fantastic</em> alternatives to iris available. One of my favorites is <a href=\"http://xray.readthedocs.org/en/stable/\">xray</a>, which exposes an API offering much of the same sort semantic handling of your netCDF data, but in a less-clunky, simpler manner. It also directly extends a good deal of the logic behind pandas, which itself is a fantastic way to manipulate timeseries/indexed datasets. Xray also works with Python 3 out of the box, and can very easily work with cartopy plotting routines (<a href=\"http://xray.readthedocs.org/en/feature-plotting/\">it even has a plotting library in the works</a>).</p>\n\n<h3 id=\"conclusions\">Conclusions</h3>\n\n<p>I still like iris. Up until this week, I was developing my analysis toolkit such that you could work with either xray/iris in any context, and seamlessly convert between the two. But the lack of Python 3 support - at the critical time <em>when I actually have some extra time to get used to the changes</em> - is enough to demote it from the top of my scientific Python stack. This doesn't even get to all the awesome goodies that xray implements, like <a href=\"http://dask.pydata.org/en/latest/\">dask integration for out-of-core computing</a>.</p>\n\n<p>So for now, there's a new workhorse in my toolkit!</p>","image":"/content/images/2015/07/MODIS_CentAm_Fires_AOD_Hysplit_4_24-1.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1436908736895,"created_by":1,"updated_at":1436910301976,"updated_by":1,"published_at":1436910301978,"published_by":1},{"id":13,"uuid":"c6ef89ae-0ea7-4cc0-a587-9df344cf1167","title":"Comment on \"Divestment in the MIT Climate Change Conversation\"","slug":"comment-on-divestment-in-the-mit-climate-change-conversation","markdown":"30 days ago, the MIT Climate Change Conversation culminated in a [Report outlining potential actions that MIT could take to address climate change][Report]. An open comment period on the Report ends today. I've been fortunate to have many conversations with my peers over the past month on the content of the Report and our own opinions on how MIT can best tackle climate change in the coming years.\n\n[Report]: http://web.mit.edu/vpr/climate/climatereport.html\n\nCuriously, many of my peers had less-than-favorable opinions about the role of divestment in the Report. This seemed to be mostly in response to a patronizing op-ed tacked on to the post-script of the Report by one of the Climate Change Conversation Committee's members (the graduate student representative) who happens to also be a co-founder of FossilFreeMIT. The post-script offers several unpersuasive arguments why divestment should feature prominently in MIT's climate action portfolio. In fact, it seems that faced with the Committee's rejection of total divestment, FFMIT has pivoted to embrace *any* divestment as a win. If you find that a bit paradoxical - since their main argument against divestment stems from moral and ethical imperatives which seem to offer little room for compromise - then you're in good company. In fact, the mantra of FFMIT these days seems to be, \"let's just do it because it can't *hurt us*, can it?\"\n\nI'd argue that it can. And I argued that in one of my comments on the [Report of the Climate Change Conversation Committee][Report], which I've reproduced below:\n\n## Divesting from Divestment\nI've been dismayed by the space that divestment has occupied in the Climate Change Conversation. It's clear that this Conversation is predicated on the influence that Fossil Free MIT has had, but the charter of the Conversation was not to simply have a \"Divestment Discussion\". The Climate Change Conversation has been critically dis-served by the focus of the divestment debate on campus, and it's time to spin that debate into a separate entity distinct from the rest of MIT's climate action plan.\n\nI understand that Mr. Supran's editorial comments in the post-script of the report follow a tradition going back to the debate on MIT's campus about the Institute's involvement in military research in relation to the Vietnam War; in that situation, a Report was crafted where there were many dissenting voices from faculty and students, and this was the model upon which the Climate Change Conversation was designed. However, I believe Mr. Supran's arguments entirely and wholly miss the mark about why divestment is controversial. Rather than focus on the myriad arguments that I and my peers have developed against divestment, here I re-iterate and further develop one explicitly (and insufficiently) addressed by Mr. Supran. \n\nUnfortunately, the divestment discussion cannabalized a significant amount of productive discussion during the Climate Change Conversation. I attended two Listening Tour Events, and at both events, over 50% of the time was occupied by the same repetitive calls for divestment. They added little productive discussion to the event. How many innovative ideas have been left on the cutting room floor because divestment has butted in to overshadow the discussion at every opportunity?\n\nBut most importantly, divestment has the potential for severe, adverse effects on MIT's research portfolio - *especially* research on the science and policy of global change. The [MIT Joint Program on the Science and Policy of Global Change](http://globalchange.mit.edu) works closely with fossil fuel companies and the energy industry, and even receives visits from top executives at those companies to learn about global change. However, contrary to Mr. Supran's assertions, the risk from divestment is far more than just losing research funding - it's a risk of losing **influential partners who are major players in the economics and policy of climate change**. If divestment - cast as a moral indictment of fossil fuel energy in general - succeeds, not only might these partners end their collaborations, but *a culture will develop where MIT researchers are discouraged from establishing these collaborations in the first place*. Suppose you're a young faculty member seeking tenure and you have the potential to collaborate with a company like Exxon on critical science and policy projects. Would you pursue them if you knew that two members of your tenure review board [signed a public letter stating that your potential collaborators of are, \"...actively working to obscure the scientific consensus around climate change\"](http://tech.mit.edu/V135/N16/faculty.html) when your potential collaboration explicitly serves the opposite purpose? \n\nSuch is the problem of morally or ethically charged actions like divestment. Despite the shallow re-assurances of Mr. Supran and others, there are significant ethical dilemmas surrounding divestment. Under no circumstances should MIT pursue divestment until these dilemmas have been properly and thoroughly vetted by at least one independent, unbiased third party - preferably including one from outside of MIT.\n\nBut this begs one further question - since divestment still requires a significant, deep reflection, why is its potential being discussed in tandem with the Climate Change Conversation at all? The Report clearly highlights two distinct avenues forward - one \"three themed\" approach with myriad potential actions, and then divestment on the side. At this point, **divestment should be divorced entirely from the Climate Change Conversation**. Let's have the \"Divestment Discussion\" that Fossil Free MIT wanted. Let's include in that discussion the many voices on campus which raise a skeptical eyebrow towards divestment, and not pretend that a majority of the campus supports it. And let's go into the debate open to the possibility that the proper divestment course of action looks nothing like the ones proposed so far.\n\nBut let's have that discussion distinct from the Climate Change Conversation, which has produced a viable forward wholly separate from the debate over divestment. This way, those of us who don't care for divestment can still fully invest in the outcome of the Climate Change Conversation, whereas those who are still arguing for it and may not be satisfied with the other solutions in the Report will have a channel to vector their disappointment. But most importantly, this would ensure that MIT's climate actions remain thorough and appropriate for tackling what is truly the greatest challenge ever to face human civilization.","html":"<p>30 days ago, the MIT Climate Change Conversation culminated in a <a href=\"http://web.mit.edu/vpr/climate/climatereport.html\">Report outlining potential actions that MIT could take to address climate change</a>. An open comment period on the Report ends today. I've been fortunate to have many conversations with my peers over the past month on the content of the Report and our own opinions on how MIT can best tackle climate change in the coming years.</p>\n\n<p>Curiously, many of my peers had less-than-favorable opinions about the role of divestment in the Report. This seemed to be mostly in response to a patronizing op-ed tacked on to the post-script of the Report by one of the Climate Change Conversation Committee's members (the graduate student representative) who happens to also be a co-founder of FossilFreeMIT. The post-script offers several unpersuasive arguments why divestment should feature prominently in MIT's climate action portfolio. In fact, it seems that faced with the Committee's rejection of total divestment, FFMIT has pivoted to embrace <em>any</em> divestment as a win. If you find that a bit paradoxical - since their main argument against divestment stems from moral and ethical imperatives which seem to offer little room for compromise - then you're in good company. In fact, the mantra of FFMIT these days seems to be, \"let's just do it because it can't <em>hurt us</em>, can it?\"</p>\n\n<p>I'd argue that it can. And I argued that in one of my comments on the <a href=\"http://web.mit.edu/vpr/climate/climatereport.html\">Report of the Climate Change Conversation Committee</a>, which I've reproduced below:</p>\n\n<h2 id=\"divestingfromdivestment\">Divesting from Divestment</h2>\n\n<p>I've been dismayed by the space that divestment has occupied in the Climate Change Conversation. It's clear that this Conversation is predicated on the influence that Fossil Free MIT has had, but the charter of the Conversation was not to simply have a \"Divestment Discussion\". The Climate Change Conversation has been critically dis-served by the focus of the divestment debate on campus, and it's time to spin that debate into a separate entity distinct from the rest of MIT's climate action plan.</p>\n\n<p>I understand that Mr. Supran's editorial comments in the post-script of the report follow a tradition going back to the debate on MIT's campus about the Institute's involvement in military research in relation to the Vietnam War; in that situation, a Report was crafted where there were many dissenting voices from faculty and students, and this was the model upon which the Climate Change Conversation was designed. However, I believe Mr. Supran's arguments entirely and wholly miss the mark about why divestment is controversial. Rather than focus on the myriad arguments that I and my peers have developed against divestment, here I re-iterate and further develop one explicitly (and insufficiently) addressed by Mr. Supran. </p>\n\n<p>Unfortunately, the divestment discussion cannabalized a significant amount of productive discussion during the Climate Change Conversation. I attended two Listening Tour Events, and at both events, over 50% of the time was occupied by the same repetitive calls for divestment. They added little productive discussion to the event. How many innovative ideas have been left on the cutting room floor because divestment has butted in to overshadow the discussion at every opportunity?</p>\n\n<p>But most importantly, divestment has the potential for severe, adverse effects on MIT's research portfolio - <em>especially</em> research on the science and policy of global change. The <a href=\"http://globalchange.mit.edu\">MIT Joint Program on the Science and Policy of Global Change</a> works closely with fossil fuel companies and the energy industry, and even receives visits from top executives at those companies to learn about global change. However, contrary to Mr. Supran's assertions, the risk from divestment is far more than just losing research funding - it's a risk of losing <strong>influential partners who are major players in the economics and policy of climate change</strong>. If divestment - cast as a moral indictment of fossil fuel energy in general - succeeds, not only might these partners end their collaborations, but <em>a culture will develop where MIT researchers are discouraged from establishing these collaborations in the first place</em>. Suppose you're a young faculty member seeking tenure and you have the potential to collaborate with a company like Exxon on critical science and policy projects. Would you pursue them if you knew that two members of your tenure review board <a href=\"http://tech.mit.edu/V135/N16/faculty.html\">signed a public letter stating that your potential collaborators of are, \"...actively working to obscure the scientific consensus around climate change\"</a> when your potential collaboration explicitly serves the opposite purpose? </p>\n\n<p>Such is the problem of morally or ethically charged actions like divestment. Despite the shallow re-assurances of Mr. Supran and others, there are significant ethical dilemmas surrounding divestment. Under no circumstances should MIT pursue divestment until these dilemmas have been properly and thoroughly vetted by at least one independent, unbiased third party - preferably including one from outside of MIT.</p>\n\n<p>But this begs one further question - since divestment still requires a significant, deep reflection, why is its potential being discussed in tandem with the Climate Change Conversation at all? The Report clearly highlights two distinct avenues forward - one \"three themed\" approach with myriad potential actions, and then divestment on the side. At this point, <strong>divestment should be divorced entirely from the Climate Change Conversation</strong>. Let's have the \"Divestment Discussion\" that Fossil Free MIT wanted. Let's include in that discussion the many voices on campus which raise a skeptical eyebrow towards divestment, and not pretend that a majority of the campus supports it. And let's go into the debate open to the possibility that the proper divestment course of action looks nothing like the ones proposed so far.</p>\n\n<p>But let's have that discussion distinct from the Climate Change Conversation, which has produced a viable forward wholly separate from the debate over divestment. This way, those of us who don't care for divestment can still fully invest in the outcome of the Climate Change Conversation, whereas those who are still arguing for it and may not be satisfied with the other solutions in the Report will have a channel to vector their disappointment. But most importantly, this would ensure that MIT's climate actions remain thorough and appropriate for tackling what is truly the greatest challenge ever to face human civilization.</p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1436990703513,"created_by":1,"updated_at":1436991301378,"updated_by":1,"published_at":1436991272610,"published_by":1},{"id":14,"uuid":"37a36dc0-cdcb-42e2-a703-b78da7c129d9","title":"Slides from JP Student Luncheon, 7/16/2015","slug":"slides-from-jp-student-luncheon-7162015","markdown":"The IPython Notebook and related media from my quick JP Student Luncheon talk is [available on my GitHub page](https://github.com/darothen/jp_lunch_summer_2015). \n\nSlides ([via nbviewer](http://nbviewer.ipython.org/format/slides/github/darothen/jp_lunch_summer_2015/blob/master/jp_slides.ipynb#/)) -\n\n<iframe src=\"http://nbviewer.ipython.org/format/slides/github/darothen/jp_lunch_summer_2015/blob/master/jp_slides.ipynb#/\" width=100% height=700></iframe>","html":"<p>The IPython Notebook and related media from my quick JP Student Luncheon talk is <a href=\"https://github.com/darothen/jp_lunch_summer_2015\">available on my GitHub page</a>. </p>\n\n<p>Slides (<a href=\"http://nbviewer.ipython.org/format/slides/github/darothen/jp_lunch_summer_2015/blob/master/jp_slides.ipynb#/\">via nbviewer</a>) -</p>\n\n<iframe src=\"http://nbviewer.ipython.org/format/slides/github/darothen/jp_lunch_summer_2015/blob/master/jp_slides.ipynb#/\" width=100% height=700></iframe>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":1437068883269,"created_by":1,"updated_at":1437069323884,"updated_by":1,"published_at":1437068990875,"published_by":1}],"users":[{"id":1,"uuid":"beafd785-84f8-4942-a1f5-f24adfdc53d9","name":"Daniel Rothenberg","slug":"daniel","password":"$2a$10$bXfLr1ng7aQrE72ZEYebOOP384Vb9FoPBqMdD714bC2UVk2V3/wlW","email":"daniel@danielrothenberg.com","image":"/content/images/2015/06/ZnYlu.png","cover":"/content/images/2015/06/cropped-copy-header_final-2.jpg","bio":"","website":"","location":"Cambridge, MA","accessibility":null,"status":"active","language":"en_US","meta_title":null,"meta_description":null,"last_login":1466301903071,"created_at":1433614738715,"created_by":1,"updated_at":1466301903072,"updated_by":1}],"roles":[{"id":1,"uuid":"d5c17d48-d0a4-4c38-b2be-b1b6d43d323f","name":"Administrator","description":"Administrators","created_at":1433614737916,"created_by":1,"updated_at":1433614737916,"updated_by":1},{"id":2,"uuid":"7c2baca9-0ba5-4184-99e6-8422b50b05c3","name":"Editor","description":"Editors","created_at":1433614737916,"created_by":1,"updated_at":1433614737916,"updated_by":1},{"id":3,"uuid":"13bb3bcd-b49d-4419-9b58-09b1636ac508","name":"Author","description":"Authors","created_at":1433614737916,"created_by":1,"updated_at":1433614737916,"updated_by":1},{"id":4,"uuid":"8da86886-be09-4312-a819-a357c189a8d5","name":"Owner","description":"Blog Owner","created_at":1433614737916,"created_by":1,"updated_at":1433614737916,"updated_by":1}],"roles_users":[{"id":1,"role_id":4,"user_id":1},{"id":2,"role_id":1,"user_id":2}],"permissions":[{"id":1,"uuid":"2d5d5ba4-af0f-4261-8b9b-a5a2dc8469b7","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":1433614737954,"created_by":1,"updated_at":1433614737954,"updated_by":1},{"id":2,"uuid":"dff1763f-8313-43e7-91d5-8aea492b2b6f","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":1433614737957,"created_by":1,"updated_at":1433614737957,"updated_by":1},{"id":3,"uuid":"2289ef7e-77db-47e7-aa01-3b56edb12ffe","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":1433614737960,"created_by":1,"updated_at":1433614737960,"updated_by":1},{"id":4,"uuid":"dd0ad9b0-e984-40c2-b259-7fd2c7ac4f06","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":1433614737963,"created_by":1,"updated_at":1433614737963,"updated_by":1},{"id":5,"uuid":"1ddc57c3-5bb9-49d7-bd72-ae84ee518da3","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":1433614737967,"created_by":1,"updated_at":1433614737967,"updated_by":1},{"id":6,"uuid":"6883f805-e093-4138-8ca8-4dcbe2c6e447","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":1433614737970,"created_by":1,"updated_at":1433614737970,"updated_by":1},{"id":7,"uuid":"b5094278-5357-44ee-b98e-59833e6f14dd","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":1433614737973,"created_by":1,"updated_at":1433614737973,"updated_by":1},{"id":8,"uuid":"bc48c102-dcd3-4588-9e72-d0d8c293002b","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":1433614737984,"created_by":1,"updated_at":1433614737984,"updated_by":1},{"id":9,"uuid":"fbd68b0a-4cb0-4850-b1c8-dadecce9dc66","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":1433614737992,"created_by":1,"updated_at":1433614737992,"updated_by":1},{"id":10,"uuid":"a331d5ef-bd4f-4279-94cc-3737ef6f8378","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":1433614737997,"created_by":1,"updated_at":1433614737997,"updated_by":1},{"id":11,"uuid":"78e88098-4274-426d-804a-057695dbf5b1","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":1433614738001,"created_by":1,"updated_at":1433614738001,"updated_by":1},{"id":12,"uuid":"c1659613-d27f-45cc-8886-fb2be2f5f6a9","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":1433614738005,"created_by":1,"updated_at":1433614738005,"updated_by":1},{"id":13,"uuid":"b0e940d3-95b7-4ae1-953b-8b14ecc10377","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":1433614738008,"created_by":1,"updated_at":1433614738008,"updated_by":1},{"id":14,"uuid":"a7cf4312-941c-4b48-97ad-72964ecd3c5d","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":1433614738013,"created_by":1,"updated_at":1433614738013,"updated_by":1},{"id":15,"uuid":"f492c564-95cd-4b52-82b5-447cb0edd74b","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":1433614738016,"created_by":1,"updated_at":1433614738016,"updated_by":1},{"id":16,"uuid":"17dbab8d-3466-4956-aae6-753cd6d73297","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":1433614738018,"created_by":1,"updated_at":1433614738018,"updated_by":1},{"id":17,"uuid":"ba7c58ee-bc95-4780-9dcc-142e9c76654f","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":1433614738021,"created_by":1,"updated_at":1433614738021,"updated_by":1},{"id":18,"uuid":"0fd14aeb-447a-4fdf-832f-5e3ae7b9dc02","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":1433614738025,"created_by":1,"updated_at":1433614738025,"updated_by":1},{"id":19,"uuid":"dbb67a3b-9774-4e71-bb44-8e999d18456c","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":1433614738028,"created_by":1,"updated_at":1433614738028,"updated_by":1},{"id":20,"uuid":"83178561-9da2-43de-b73b-dc0cd59b9027","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":1433614738031,"created_by":1,"updated_at":1433614738031,"updated_by":1},{"id":21,"uuid":"7f483d74-e59f-4d44-b8a9-3ce275eeb344","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":1433614738033,"created_by":1,"updated_at":1433614738033,"updated_by":1},{"id":22,"uuid":"d461efc3-435e-44df-8474-6be7c561e66f","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":1433614738036,"created_by":1,"updated_at":1433614738036,"updated_by":1},{"id":23,"uuid":"914726fb-a0e1-463c-a48e-35b3cada319c","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":1433614738039,"created_by":1,"updated_at":1433614738039,"updated_by":1},{"id":24,"uuid":"752d68a1-3428-41b2-b856-220b9a8a1d25","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":1433614738042,"created_by":1,"updated_at":1433614738042,"updated_by":1},{"id":25,"uuid":"39aaf747-906f-4eb9-96a2-5c8eda7522f3","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":1433614738045,"created_by":1,"updated_at":1433614738045,"updated_by":1},{"id":26,"uuid":"f3355b9c-0c6f-4ec2-9a2a-144dc2c5b64b","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":1433614738049,"created_by":1,"updated_at":1433614738049,"updated_by":1},{"id":27,"uuid":"c5002b3b-2748-45ba-882c-1c01951024c3","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":1433614738056,"created_by":1,"updated_at":1433614738056,"updated_by":1},{"id":28,"uuid":"8ae20ab0-4380-4bb3-864b-5f97dcbf8bb3","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":1433614738059,"created_by":1,"updated_at":1433614738059,"updated_by":1},{"id":29,"uuid":"b21b1fb0-0820-4f54-a7f2-972405ebad6a","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":1433614738064,"created_by":1,"updated_at":1433614738064,"updated_by":1},{"id":30,"uuid":"c4912690-a8a1-4db4-a2a0-9cc5eea0b172","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":1433614738068,"created_by":1,"updated_at":1433614738068,"updated_by":1}],"permissions_users":[],"permissions_roles":[{"id":1,"role_id":1,"permission_id":1},{"id":2,"role_id":1,"permission_id":2},{"id":3,"role_id":1,"permission_id":3},{"id":4,"role_id":1,"permission_id":4},{"id":5,"role_id":1,"permission_id":5},{"id":6,"role_id":1,"permission_id":6},{"id":7,"role_id":1,"permission_id":7},{"id":8,"role_id":1,"permission_id":8},{"id":9,"role_id":1,"permission_id":9},{"id":10,"role_id":1,"permission_id":10},{"id":11,"role_id":1,"permission_id":11},{"id":12,"role_id":1,"permission_id":12},{"id":13,"role_id":1,"permission_id":13},{"id":14,"role_id":1,"permission_id":14},{"id":15,"role_id":1,"permission_id":15},{"id":16,"role_id":1,"permission_id":16},{"id":17,"role_id":1,"permission_id":17},{"id":18,"role_id":1,"permission_id":18},{"id":19,"role_id":1,"permission_id":19},{"id":20,"role_id":1,"permission_id":20},{"id":21,"role_id":1,"permission_id":21},{"id":22,"role_id":1,"permission_id":22},{"id":23,"role_id":1,"permission_id":23},{"id":24,"role_id":1,"permission_id":24},{"id":25,"role_id":1,"permission_id":25},{"id":26,"role_id":1,"permission_id":26},{"id":27,"role_id":1,"permission_id":27},{"id":28,"role_id":1,"permission_id":28},{"id":29,"role_id":1,"permission_id":29},{"id":30,"role_id":1,"permission_id":30},{"id":31,"role_id":2,"permission_id":8},{"id":32,"role_id":2,"permission_id":9},{"id":33,"role_id":2,"permission_id":10},{"id":34,"role_id":2,"permission_id":11},{"id":35,"role_id":2,"permission_id":12},{"id":36,"role_id":2,"permission_id":13},{"id":37,"role_id":2,"permission_id":14},{"id":38,"role_id":2,"permission_id":16},{"id":39,"role_id":2,"permission_id":17},{"id":40,"role_id":2,"permission_id":18},{"id":41,"role_id":2,"permission_id":19},{"id":42,"role_id":2,"permission_id":20},{"id":43,"role_id":2,"permission_id":21},{"id":44,"role_id":2,"permission_id":24},{"id":45,"role_id":2,"permission_id":25},{"id":46,"role_id":2,"permission_id":26},{"id":47,"role_id":2,"permission_id":27},{"id":48,"role_id":2,"permission_id":28},{"id":49,"role_id":2,"permission_id":29},{"id":50,"role_id":2,"permission_id":30},{"id":51,"role_id":3,"permission_id":8},{"id":52,"role_id":3,"permission_id":9},{"id":53,"role_id":3,"permission_id":11},{"id":54,"role_id":3,"permission_id":13},{"id":55,"role_id":3,"permission_id":14},{"id":56,"role_id":3,"permission_id":16},{"id":57,"role_id":3,"permission_id":17},{"id":58,"role_id":3,"permission_id":18},{"id":59,"role_id":3,"permission_id":20},{"id":60,"role_id":3,"permission_id":24},{"id":61,"role_id":3,"permission_id":25},{"id":62,"role_id":3,"permission_id":30}],"permissions_apps":[],"settings":[{"id":1,"uuid":"ae09e7ff-a7a8-46e3-a92a-ae34da9574fa","key":"databaseVersion","value":"003","type":"core","created_at":1433614738724,"created_by":1,"updated_at":1433614738724,"updated_by":1},{"id":2,"uuid":"32eea360-0a67-4bd8-a9bd-b582f05f7858","key":"dbHash","value":"17e3e6d6-e855-4842-a858-1c16ded874a8","type":"core","created_at":1433614738728,"created_by":1,"updated_at":1433614738801,"updated_by":1},{"id":3,"uuid":"3f28eec9-dbc3-4fa8-bb63-8d4314a27125","key":"nextUpdateCheck","value":"1466388295","type":"core","created_at":1433614738728,"created_by":1,"updated_at":1466301894985,"updated_by":1},{"id":4,"uuid":"9016d087-7e1c-4121-a89c-9ec8efbec46c","key":"displayUpdateNotification","value":null,"type":"core","created_at":1433614738728,"created_by":1,"updated_at":1433614738728,"updated_by":1},{"id":5,"uuid":"0d10c3d7-efec-4d6f-892f-846d7e16507d","key":"title","value":"Daniel Rothenberg","type":"blog","created_at":1433614738729,"created_by":1,"updated_at":1434068321567,"updated_by":1},{"id":6,"uuid":"8fbcc91e-71f7-40eb-b637-b5bc3b457ce6","key":"description","value":"","type":"blog","created_at":1433614738729,"created_by":1,"updated_at":1434068321569,"updated_by":1},{"id":7,"uuid":"bb98c41b-a6d7-4f15-bd29-1b54abf39492","key":"email","value":"darothen@mit.edu","type":"blog","created_at":1433614738730,"created_by":1,"updated_at":1434068321570,"updated_by":1},{"id":8,"uuid":"66b86557-2fa7-4c8c-a60e-227725e6765b","key":"logo","value":"/content/images/2015/06/10904606_10203510995794417_5476723049500214533_o.jpg","type":"blog","created_at":1433614738730,"created_by":1,"updated_at":1434068321570,"updated_by":1},{"id":9,"uuid":"81c59d66-6de7-4634-9eab-a321c06d6485","key":"cover","value":"/content/images/2015/06/4479858386_7a9bfaff05_o.jpg","type":"blog","created_at":1433614738730,"created_by":1,"updated_at":1434068321570,"updated_by":1},{"id":10,"uuid":"2dc0be9a-44bc-4534-bd77-b15fde0c49f2","key":"defaultLang","value":"en_US","type":"blog","created_at":1433614738730,"created_by":1,"updated_at":1434068321571,"updated_by":1},{"id":11,"uuid":"a30670ea-5178-4b6e-8699-c12f9581b5e7","key":"postsPerPage","value":"5","type":"blog","created_at":1433614738730,"created_by":1,"updated_at":1434068321571,"updated_by":1},{"id":12,"uuid":"79e8bf5d-9fce-42ba-9a32-72df5e57b886","key":"forceI18n","value":"true","type":"blog","created_at":1433614738731,"created_by":1,"updated_at":1434068321572,"updated_by":1},{"id":13,"uuid":"0f766c31-a455-4b68-9de2-f4c3f44c7172","key":"permalinks","value":"/:slug/","type":"blog","created_at":1433614738731,"created_by":1,"updated_at":1434068321572,"updated_by":1},{"id":14,"uuid":"f36bc89e-14a2-41fa-be92-abf7b669c0b8","key":"ghost_head","value":"<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-9479992-1', 'auto');\n  ga('send', 'pageview');\n\n</script>","type":"blog","created_at":1433614738731,"created_by":1,"updated_at":1434068321576,"updated_by":1},{"id":15,"uuid":"5d46fe0b-ac43-4825-97cd-76d1f63275c1","key":"ghost_foot","value":"","type":"blog","created_at":1433614738731,"created_by":1,"updated_at":1434068321576,"updated_by":1},{"id":16,"uuid":"6c0ec452-3f4f-416d-88a5-8aee707f00e3","key":"labs","value":"{}","type":"blog","created_at":1433614738731,"created_by":1,"updated_at":1434068321577,"updated_by":1},{"id":17,"uuid":"4686879d-ce82-41bc-a22e-8882d5f9cdb2","key":"navigation","value":"[{\"label\":\"Blog\",\"url\":\"http://www.danielrothenberg.com\"},{\"label\":\"About\",\"url\":\"http://www.danielrothenberg.com/about\"},{\"label\":\"Projects\",\"url\":\"http://www.danielrothenberg.com/projects\"}]","type":"blog","created_at":1433614738731,"created_by":1,"updated_at":1434068321578,"updated_by":1},{"id":18,"uuid":"d69930f1-9a72-4ef5-b1b7-199899e6fa42","key":"activeApps","value":"[]","type":"app","created_at":1433614738731,"created_by":1,"updated_at":1433614738731,"updated_by":1},{"id":19,"uuid":"4f04b1ee-7b76-4d93-b0b7-e2e68625f803","key":"installedApps","value":"[]","type":"app","created_at":1433614738731,"created_by":1,"updated_at":1466016785822,"updated_by":1},{"id":20,"uuid":"b24e8809-a287-4c74-bc09-cb428426e346","key":"activeTheme","value":"danielrothenberg","type":"theme","created_at":1433614738731,"created_by":1,"updated_at":1434068321573,"updated_by":1}],"tags":[{"id":1,"uuid":"45cf148c-33ab-43cd-88b0-a8a340a47a1e","name":"Getting Started","slug":"getting-started","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1433614737915,"created_by":1,"updated_at":1433614737915,"updated_by":1},{"id":2,"uuid":"5ae7f55c-34d3-417c-bb7e-7493a2d9d5b3","name":"MIT","slug":"mit","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1433769313612,"created_by":1,"updated_at":1433769313612,"updated_by":1},{"id":3,"uuid":"094fd8f7-5b91-407e-835f-f4c30572579c","name":"Climate Change Conversation","slug":"climate-change-conversation","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1433769313619,"created_by":1,"updated_at":1433769313619,"updated_by":1},{"id":4,"uuid":"bf6da02c-ddfb-44c1-8d9b-b813e8aa3c99","name":"Divestment","slug":"divestment","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1433769313623,"created_by":1,"updated_at":1433769313623,"updated_by":1},{"id":5,"uuid":"019504e0-ecf1-4580-bfa9-ee6fcfd7f14e","name":"op-ed","slug":"op-ed","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1433769313627,"created_by":1,"updated_at":1433769313627,"updated_by":1},{"id":6,"uuid":"9af3d119-50e4-4e74-ac01-f9c2485e213e","name":"python","slug":"python","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435856474147,"created_by":1,"updated_at":1435856474147,"updated_by":1},{"id":7,"uuid":"9d2c1d59-ae35-4747-a361-56d0239a691e","name":"cartopy","slug":"cartopy","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435856474153,"created_by":1,"updated_at":1435856474153,"updated_by":1},{"id":8,"uuid":"54fbf861-66ec-4220-9ce3-004e3cbcf868","name":"iris","slug":"iris","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435856474156,"created_by":1,"updated_at":1435856474156,"updated_by":1},{"id":9,"uuid":"e7906f9f-b900-441c-b8d1-7e2b2ff183b0","name":"xray","slug":"xray","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435856474159,"created_by":1,"updated_at":1435856474159,"updated_by":1},{"id":10,"uuid":"7a2e7bfe-fdd3-47ef-9741-2155d0111f00","name":"visualization","slug":"visualization","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435856474162,"created_by":1,"updated_at":1435856474162,"updated_by":1},{"id":11,"uuid":"ed4e923f-7501-4c70-b71d-768416e94d90","name":"netCDF","slug":"netcdf","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435856474165,"created_by":1,"updated_at":1435856474165,"updated_by":1},{"id":12,"uuid":"54c463c3-11c6-4683-b9bb-c0054d127380","name":"git","slug":"git","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435944320924,"created_by":1,"updated_at":1435944320924,"updated_by":1},{"id":13,"uuid":"5f97e44d-983c-4c26-96d3-eb0bf464f92c","name":"osx","slug":"osx","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435944320930,"created_by":1,"updated_at":1435944320930,"updated_by":1},{"id":14,"uuid":"92fcf1fb-b39c-4483-9697-989db61cab5f","name":"CUDA","slug":"cuda","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435944376638,"created_by":1,"updated_at":1435944376638,"updated_by":1},{"id":15,"uuid":"28bc9bc2-cec4-4661-bc66-deadec89bfea","name":"algorithm","slug":"algorithm","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435944376642,"created_by":1,"updated_at":1435944376642,"updated_by":1},{"id":16,"uuid":"da6f42bb-1d2a-4af7-bd94-6016bbcb05ad","name":"numbapro","slug":"numbapro","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435944376645,"created_by":1,"updated_at":1435944376645,"updated_by":1},{"id":17,"uuid":"a46f9b42-1699-4e65-9acd-aa890596a115","name":"GPGPU","slug":"gpgpu","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1435944376649,"created_by":1,"updated_at":1435944376649,"updated_by":1},{"id":18,"uuid":"8e06c1cc-659f-4a73-94bc-8c0c44b41ac7","name":"severe weather","slug":"severe-weather","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436805820515,"created_by":1,"updated_at":1436805820515,"updated_by":1},{"id":19,"uuid":"ec110e0e-4737-402b-8912-4127ae35e475","name":"forecasting","slug":"forecasting","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436805820520,"created_by":1,"updated_at":1436805820520,"updated_by":1},{"id":20,"uuid":"219baca6-203b-41b7-aecf-28237815a40e","name":"lousville","slug":"lousville","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436805820525,"created_by":1,"updated_at":1436805820525,"updated_by":1},{"id":21,"uuid":"067b7f5f-c669-4508-904f-9485159c3ad2","name":"nowcasting","slug":"nowcasting","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436805820529,"created_by":1,"updated_at":1436805820529,"updated_by":1},{"id":22,"uuid":"81bcd0a3-ca72-46f2-8a03-5d92019621f8","name":"Py","slug":"py","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436908740039,"created_by":1,"updated_at":1436908740039,"updated_by":1},{"id":23,"uuid":"44d82dbe-4d80-4ae4-b905-6a591bfbcf5e","name":"data","slug":"data","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436908774390,"created_by":1,"updated_at":1436908774390,"updated_by":1},{"id":24,"uuid":"f4bd0155-f1d0-430a-a689-5ef8ffdcbd4c","name":"divest","slug":"divest","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1436990916133,"created_by":1,"updated_at":1436990916133,"updated_by":1},{"id":25,"uuid":"e6c5ab36-4608-4c3a-be10-d352673a613a","name":"slides","slug":"slides","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1437069323892,"created_by":1,"updated_at":1437069323892,"updated_by":1},{"id":26,"uuid":"b75952e7-35e5-4601-8d4d-f69e07fcd478","name":"Joint Program","slug":"joint-program","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1437069323913,"created_by":1,"updated_at":1437069323913,"updated_by":1},{"id":27,"uuid":"84961d4b-005e-4550-a822-a78814624979","name":"luncheon","slug":"luncheon","description":null,"image":null,"hidden":0,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":1437069323917,"created_by":1,"updated_at":1437069323917,"updated_by":1}],"posts_tags":[{"id":42,"post_id":3,"tag_id":2},{"id":43,"post_id":3,"tag_id":3},{"id":44,"post_id":3,"tag_id":4},{"id":45,"post_id":3,"tag_id":5},{"id":46,"post_id":1,"tag_id":1},{"id":53,"post_id":10,"tag_id":6},{"id":54,"post_id":10,"tag_id":7},{"id":55,"post_id":10,"tag_id":8},{"id":56,"post_id":10,"tag_id":9},{"id":57,"post_id":10,"tag_id":10},{"id":58,"post_id":10,"tag_id":11},{"id":59,"post_id":9,"tag_id":12},{"id":60,"post_id":9,"tag_id":13},{"id":61,"post_id":6,"tag_id":6},{"id":62,"post_id":6,"tag_id":14},{"id":63,"post_id":6,"tag_id":15},{"id":64,"post_id":6,"tag_id":16},{"id":65,"post_id":6,"tag_id":17},{"id":202,"post_id":11,"tag_id":18},{"id":203,"post_id":11,"tag_id":19},{"id":204,"post_id":11,"tag_id":20},{"id":205,"post_id":11,"tag_id":21},{"id":517,"post_id":12,"tag_id":6},{"id":518,"post_id":12,"tag_id":8},{"id":519,"post_id":12,"tag_id":9},{"id":520,"post_id":12,"tag_id":11},{"id":521,"post_id":12,"tag_id":23},{"id":579,"post_id":13,"tag_id":2},{"id":580,"post_id":13,"tag_id":3},{"id":581,"post_id":13,"tag_id":24},{"id":582,"post_id":14,"tag_id":6},{"id":583,"post_id":14,"tag_id":25},{"id":584,"post_id":14,"tag_id":26},{"id":585,"post_id":14,"tag_id":27}],"apps":[],"app_settings":[],"app_fields":[]}}]}